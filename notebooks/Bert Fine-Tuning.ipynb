{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from mangoes.modeling import BERTForSequenceClassification, BERTForQuestionAnswering, BERTForCoreferenceResolution, \\\n",
    "    BERTForMultipleChoice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users can fine tune a pretrained model on downstream tasks, using the same interface as the pretraining and feature extraction classes. Below are some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common fine-tuning task is text classification, including text sequence classification (ie, sentiment analysis) or token classification (ie, named entity classification). Here we will show an example of sentiment analysis, but the process is the same for token classification. \n",
    "The first step is to load the pretrained base bert model. We can load the pretrained model we saved in the pretraining demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model_output/ were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./model_output/ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/joseph/.pyenv/versions/3.6.12/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = \"./model_output/\"\n",
    "\n",
    "# Since we saved the trained tokenizer with the model, we can pass the same directry for the tokenizer argument.\n",
    "# We pass the task labels when loading, as these are needed when instaniating the model.\n",
    "loaded_model = BERTForSequenceClassification.load(saved_model_dir, saved_model_dir, labels=[\"pos\", \"neg\"],\n",
    "                                                  label2id={'neg': 0, 'pos': 1})\n",
    "\n",
    "# alternatively, we could have loaded a pretrained bert model from huggingface:\n",
    "# loaded_model = BERTForSequenceClassification.load(\"bert-base-uncased\", \"bert-base-uncased\", \n",
    "#                                                   labels=[\"pos\", \"neg\"], label2id={'neg': 0, 'pos': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "\n",
    "We'll use the IMDb sentiment analysis dataset. Here we load it using the nlp package, then extract the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp import load_dataset\n",
    "\n",
    "train_dataset, test_dataset = load_dataset('imdb', split=['train', 'test'])\n",
    "\n",
    "train_texts = [x['text'] for x in train_dataset]\n",
    "train_targets = [x['label'] for x in train_dataset]\n",
    "test_texts = [x['text'] for x in test_dataset]\n",
    "test_targets = [x['label'] for x in test_dataset]\n",
    "\n",
    "# for the sake of the demo, we'll truncate the datasets so the trainings take less time\n",
    "# we take from the beginning and end of the dataset to get a mix of pos and neg examples\n",
    "\n",
    "train_texts = train_texts[:150] + train_texts[-150:]\n",
    "train_targets = train_targets[:150] + train_targets[-150:]\n",
    "test_texts = test_texts[:150] + test_texts[-150:]\n",
    "test_targets = test_targets[:150] + test_targets[-150:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate metrics during the training of the model by creating and passing in a compute_metrics function, as described here (https://huggingface.co/transformers/training.html#trainer):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the train method, we can use the raw data as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.701800</td>\n",
       "      <td>0.695033</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.584200</td>\n",
       "      <td>31.302000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joseph/.pyenv/versions/3.6.12/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "loaded_model.train(train_text=train_texts, train_targets=train_targets,\n",
    "                   eval_text=test_texts, eval_targets=test_targets,\n",
    "                   output_dir=\"./model_ckpts/\", max_len=512, num_train_epochs=1, \n",
    "                   per_device_train_batch_size=32, per_device_eval_batch_size=16,\n",
    "                   logging_steps=10, learning_rate=0.0001, evaluation_strategy=\"epoch\",\n",
    "                   compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or initialized torch.Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:34, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.696100</td>\n",
       "      <td>0.694875</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.605900</td>\n",
       "      <td>31.231000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mangoes.modeling import MangoesTextClassificationDataset\n",
    "\n",
    "train_dataset = MangoesTextClassificationDataset(train_texts, train_targets, loaded_model.tokenizer, \n",
    "                                                 max_len=512, label2id={'neg': 0, 'pos': 1})\n",
    "eval_dataset = MangoesTextClassificationDataset(test_texts, test_targets, loaded_model.tokenizer, \n",
    "                                                max_len=512, label2id={'neg': 0, 'pos': 1})\n",
    "\n",
    "loaded_model.train(train_dataset=train_dataset, eval_dataset=eval_dataset,   \n",
    "                   output_dir=\"./model_ckpts/\", max_len=512, num_train_epochs=1, \n",
    "                   per_device_train_batch_size=32, per_device_eval_batch_size=16,\n",
    "                   logging_steps=10, learning_rate=0.0001, evaluation_strategy=\"epoch\",\n",
    "                   compute_metrics=compute_metrics, seed=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We can use the predict function for direct sentiment prediction, or generate_outputs for more detailed outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'pos', 'score': 0.5291166305541992}]\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(\"This is a good movie\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['logits', 'hidden_states', 'attentions', 'offset_mappings'])\n"
     ]
    }
   ],
   "source": [
    "outputs = loaded_model.generate_outputs(\"This is a good movie\", output_hidden_states=True, output_attentions=True)\n",
    "print(outputs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading\n",
    "Users can save and load finetuned models using the same save and load methods. Here we can load a finetuned model that has been uploaded to Huggingface's servers, then use it to classify text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'pos', 'score': 0.9922362565994263}]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = BERTForSequenceClassification.load(\"textattack/bert-base-uncased-imdb\", \n",
    "                                                  \"textattack/bert-base-uncased-imdb\", \n",
    "                                                  labels=[\"pos\", \"neg\"], label2id={'neg': 0, 'pos': 1})\n",
    "\n",
    "predictions = loaded_model.predict(\"This is a good movie\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "Question answering is another common fine-tuning task.\n",
    "The first step is again to load the pretrained base bert model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model_output/ were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ./model_output/ and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = \"./model_output/\"\n",
    "\n",
    "# Since we saved the trained tokenizer with the model, we can pass the same directry for the tokenizer argument.\n",
    "# We pass the task labels when loading, as these are needed when instaniating the model.\n",
    "loaded_model = BERTForQuestionAnswering.load(saved_model_dir, saved_model_dir)\n",
    "\n",
    "# alternatively, we could have loaded a pretrained bert model from huggingface:\n",
    "# loaded_model = BERTForQuestionAnswering.load(\"bert-base-uncased\", \"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "We'll use the Squad dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp import load_dataset\n",
    "\n",
    "train_dataset, eval_dataset = load_dataset('squad', split=['train', 'validation'])\n",
    "train_contexts = [x['context'] for x in train_dataset][:250]\n",
    "train_questions = [x['question'] for x in train_dataset][:250]\n",
    "train_starts = [x['answers']['answer_start'][0] for x in train_dataset][:250]\n",
    "train_answers = [x['answers']['text'][0] for x in train_dataset][:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "We can call train by passing the raw data or torch.Datasets to the train function. Here we'll pass the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 250/250 [00:03<00:00, 71.26it/s]\n",
      "add example index and unique id: 100%|██████████| 250/250 [00:00<00:00, 414620.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:24, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.961200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.878800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model.train(train_question_texts=train_questions, train_context_texts=train_contexts,\n",
    "                   train_answer_texts=train_answers, train_start_indices=train_starts,\n",
    "                   output_dir=\"./model_ckpts/\", num_train_epochs=1, learning_rate=0.00005,\n",
    "                   per_device_train_batch_size=32, logging_steps=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could instantiated a transformers.Trainer object directly and pass it to the train function. Additionally, the base BERT model can be frozen and we can only train the task heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|██████████| 250/250 [00:03<00:00, 70.83it/s]\n",
      "add example index and unique id: 100%|██████████| 250/250 [00:00<00:00, 696728.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:13, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.846700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>5.849100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.8467, 'learning_rate': 3.571428571428572e-05, 'epoch': 0.29}\n",
      "{'loss': 5.8461, 'learning_rate': 2.1428571428571428e-05, 'epoch': 0.57}\n",
      "{'loss': 5.8491, 'learning_rate': 7.142857142857143e-06, 'epoch': 0.86}\n",
      "{'train_runtime': 14.7859, 'train_samples_per_second': 0.947, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, PrinterCallback\n",
    "from mangoes.modeling import MangoesQuestionAnsweringDataset\n",
    "\n",
    "train_dataset = MangoesQuestionAnsweringDataset(loaded_model.tokenizer, train_questions,\n",
    "                                                train_contexts, train_answers, train_starts)\n",
    "\n",
    "train_args = TrainingArguments(output_dir=\"./model_ckpts/\", num_train_epochs=1, learning_rate=0.00005,\n",
    "                                            per_device_train_batch_size=32, logging_steps=4)\n",
    "trainer = Trainer(loaded_model.model, args=train_args, train_dataset=train_dataset,\n",
    "                  tokenizer=loaded_model.tokenizer, callbacks=[PrinterCallback])\n",
    "\n",
    "loaded_model.train(trainer=trainer, freeze_base=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "We can use the predict or generate_outputs functions for model inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 3.868541170959361e-05, 'start': 260, 'end': 287, 'answer': 'Me Omnes\". Next to the Main'}]\n",
      "dict_keys(['start_logits', 'end_logits', 'hidden_states', 'offset_mappings'])\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(question=train_questions[0], context=train_contexts[0])\n",
    "print(predictions)\n",
    "outputs = loaded_model.generate_outputs(question=train_questions[0], context=train_contexts[0], output_hidden_states=True)\n",
    "print(outputs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading\n",
    "Users can save and load finetuned models using the same save and load methods. Here we can load a finetuned model that has been uploaded to Huggingface's servers, then use it to answer a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.7772578001022339, 'start': 19, 'end': 32, 'answer': 'in the context'}]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = BERTForQuestionAnswering.load(\"csarron/bert-base-uncased-squad-v1\", \n",
    "                                             \"csarron/bert-base-uncased-squad-v1\")\n",
    "\n",
    "predictions = loaded_model.predict(question=\"Where does the answer reside?\", context=\"The answer resides in the context\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Choice\n",
    "Another fine-tuning task is training a model to answer multiple choice questions. We'll start by loading the base model we pretrained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./model_output/ were not used when initializing BertForMultipleChoice: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at ./model_output/ and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = \"./model_output/\"\n",
    "\n",
    "loaded_model = BERTForMultipleChoice.load(saved_model_dir, saved_model_dir)\n",
    "\n",
    "# alternatively, we could have loaded a pretrained bert model from huggingface:\n",
    "# loaded_model = BERTForMultipleChoice.load(\"bert-base-cased\", \"SpanBERT/spanbert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "We'll use a subset of the hellaswag (extension of SWAG) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them.\n",
      "['the pans contain egg yolks and baking soda.', 'the pans are then sprinkled with brown sugar.', 'the pans are placed in a strainer on the counter.', 'the pans are filled with pastries and loaded into the oven.']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from nlp import load_dataset\n",
    "\n",
    "train_dataset, eval_dataset = load_dataset('hellaswag', split=['train', 'validation'])\n",
    "train_contexts = [x['ctx_a'] for x in train_dataset][:65]\n",
    "train_choices = [[x['ctx_b'] + \" \" + ending for ending in x['endings']] for x in train_dataset][:65]\n",
    "train_labels = [x['label'] for x in train_dataset][:65]\n",
    "eval_contexts = [x['ctx_a'] for x in eval_dataset][:100]\n",
    "eval_choices = [[x['ctx_b'] + \" \" + ending for ending in x['endings']] for x in eval_dataset][:100]\n",
    "eval_labels = [x['label'] for x in eval_dataset][:100]\n",
    "\n",
    "print(train_contexts[1])\n",
    "print(train_choices[1])\n",
    "print(train_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Next, we can pass this raw data into the train function along with any training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.378100</td>\n",
       "      <td>1.386250</td>\n",
       "      <td>7.331200</td>\n",
       "      <td>13.640000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model.train(train_question_texts=train_contexts, eval_question_texts=eval_contexts,\n",
    "                   train_choices_texts=train_choices, eval_choices_texts=eval_choices,\n",
    "                   train_labels=train_labels, eval_labels=eval_labels, learning_rate=0.0005,\n",
    "                   per_device_train_batch_size=8, per_device_eval_batch_size=8, logging_steps=4,\n",
    "                   max_len=384, output_dir=\"./model_ckpts/\", num_train_epochs=1, task_learn_rate=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you could instantiate torch Datasets and pass them as data arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.326000</td>\n",
       "      <td>1.386535</td>\n",
       "      <td>7.637400</td>\n",
       "      <td>13.093000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mangoes.modeling import MangoesMultipleChoiceDataset\n",
    "\n",
    "train_dataset = MangoesMultipleChoiceDataset(loaded_model.tokenizer, train_contexts, \n",
    "                                             train_choices, train_labels, 384)\n",
    "\n",
    "eval_dataset = MangoesMultipleChoiceDataset(loaded_model.tokenizer, eval_contexts, \n",
    "                                             eval_choices, eval_labels, 384)\n",
    "\n",
    "loaded_model.train(train_dataset=train_dataset, eval_dataset=eval_dataset, per_device_train_batch_size=8, \n",
    "                   per_device_eval_batch_size=8, logging_steps=4, output_dir=\"./model_ckpts/\", \n",
    "                   learning_rate=0.005, num_train_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "We can use the predict or generate_outputs functions for model inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'answer_index': 0, 'score': 0.5091835856437683, 'answer_text': 'It said meow'}]\n",
      "odict_keys(['logits', 'offset_mappings'])\n",
      "tensor([[1.2972, 1.2604]])\n"
     ]
    }
   ],
   "source": [
    "questions = \"What did the cat say to the dog?\"\n",
    "choices = [\"It said meow\", \"it said bark\"]\n",
    "\n",
    "\n",
    "predictions = loaded_model.predict(questions, choices)\n",
    "print(predictions)\n",
    "outputs = loaded_model.generate_outputs(questions, choices)\n",
    "print(outputs.keys())\n",
    "print(outputs['logits'])   # pre-softmax scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.save(\"output_directory/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-reference Resolution\n",
    "Another fine-tuning task is co-reference resolution. We'll start by loading the base model we pretrained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForCoreferenceResolutionBase were not initialized from the model checkpoint at SpanBERT/spanbert-base-cased and are newly initialized: ['span_attend_projection.weight', 'span_attend_projection.bias', 'mention_scorer.0.weight', 'mention_scorer.0.bias', 'mention_scorer.3.weight', 'mention_scorer.3.bias', 'width_scores.0.weight', 'width_scores.0.bias', 'width_scores.3.weight', 'width_scores.3.bias', 'fast_antecedent_projection.weight', 'fast_antecedent_projection.bias', 'slow_antecedent_scorer.0.weight', 'slow_antecedent_scorer.0.bias', 'slow_antecedent_scorer.3.weight', 'slow_antecedent_scorer.3.bias', 'slow_antecedent_projection.weight', 'slow_antecedent_projection.bias', 'genre_embeddings.weight', 'distance_embeddings.weight', 'slow_distance_embeddings.weight', 'distance_projection.weight', 'distance_projection.bias', 'same_speaker_embeddings.weight', 'span_width_embeddings.weight', 'span_width_prior_embeddings.weight', 'segment_dist_embeddings.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = \"./model_output/\"\n",
    "\n",
    "# loaded_model = BERTForCoreferenceResolution.load(saved_model_dir, saved_model_dir, use_metadata=True)\n",
    "\n",
    "# alternatively, we could have loaded a pretrained bert model from huggingface:\n",
    "loaded_model = BERTForCoreferenceResolution.load(\"bert-base-cased\", \"SpanBERT/spanbert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "First, we load a small subset of the ONTONOTES dataset for demo purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['sentences', 'clusters', 'speakers', 'genres'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('data/coref_data.json') as json_file:\n",
    "    data_dict = json.load(json_file)\n",
    "print(data_dict.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Next, we can pass this raw data into the train function along with any training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../mangoes/modeling/coref.py:256: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.cat([dummy_scores, top_antecedent_scores], 1))  # [top_cand, top_ant + 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='6' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6/6 00:32, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>361.961548</td>\n",
       "      <td>9.783100</td>\n",
       "      <td>0.613000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model.train(output_dir=\"./model_ckpts/\", train_documents=data_dict[\"sentences\"][:6], \n",
    "                   train_cluster_ids=data_dict[\"clusters\"][:6], train_speaker_ids=data_dict[\"speakers\"][:6],\n",
    "                   train_genres=data_dict[\"genres\"][:6], \n",
    "                   eval_documents=data_dict[\"sentences\"][6:12],\n",
    "                   eval_cluster_ids=data_dict[\"clusters\"][6:12], eval_speaker_ids=data_dict[\"speakers\"][6:12],\n",
    "                   eval_genres=data_dict[\"genres\"][6:12],\n",
    "                   num_train_epochs=1, learning_rate=0.0005,\n",
    "                   logging_steps=2, task_learn_rate=0.001, evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving/Loading\n",
    "The save and load methods can be used to save a trained model, and load either a pretrained base model for fine-tuning or an already fine-tuned model for inference. Here we'll load an already fine-tuned model (skip this cell if this presaved model is not available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = BERTForCoreferenceResolution.load(\"./coref_model/\", \"./coref_model/\", use_metadata=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "The predict and generate_outputs functions can be called to use the model for inference. The predict function gives direct co-reference predictions, while the generate_outputs functions returns all the antecedent and mention scores and indices, as well as the hidden states and attention matrices, if asked for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As the year 2006 ended , so did a big hush - hush \" deal . \"', 'Caijing Magazine described it as \" a quiet change of ownership for this vast business empire . \"', 'These were the final few steps as Shandong Luneng Group \" completed \" its privatization .', 'In the past , when I heard the big name of Luneng Group , I usually would link it with soccer .', 'I could never expect it is a 73.805 billion yuan giant .']\n"
     ]
    }
   ],
   "source": [
    "# pre-tokenized\n",
    "document = data_dict[\"sentences\"][50][7:12]\n",
    "speakers = data_dict[\"speakers\"][50][7:12]\n",
    "genre = data_dict[\"genres\"][50]\n",
    "\n",
    "# not pre-tokenized\n",
    "input_doc = [' '.join(sent) for sent in document]\n",
    "input_speaker = [sent[0] for sent in speakers]\n",
    "print(input_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'big', 'h', '##ush', '-', 'h', '##ush', '\"', 'deal'], ['it']]\n",
      "[['this', 'vast', 'business', 'empire'], ['Shan', '##dong', 'Lu', '##nen', '##g', 'Group'], ['its'], ['Lu', '##nen', '##g', 'Group'], ['it']]\n",
      "[['I'], ['I'], ['I']]\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(document, pre_tokenized=True, speaker_ids=speakers, genre=genre)\n",
    "\n",
    "for coref in predictions:\n",
    "    print(coref[\"cluster_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'candidate_starts', 'candidate_ends', 'candidate_mention_scores', 'top_span_starts', 'top_span_ends', 'top_antecedents', 'top_antecedent_scores', 'flattened_ids', 'flattened_text'])\n"
     ]
    }
   ],
   "source": [
    "outputs = loaded_model.generate_outputs(input_doc, pre_tokenized=False, speaker_ids=input_speaker, genre=genre)\n",
    "print(outputs.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
