{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import mangoes\n",
    "import nltk\n",
    "import string \n",
    "import pprint \n",
    "import os \n",
    "import datetime \n",
    "import logging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-enzyme",
   "metadata": {},
   "source": [
    "Read more for \n",
    "\n",
    "https://github.com/UniversalDependencies/UD_English-EWT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or specify date to saved ones\n",
    "# eg: date = \"2021-03-24-15-23\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join(os.path.abspath(''), \"output/{}\".format(date))\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    print(\"made a dir: \", OUTPUT_PATH)\n",
    "    os.makedirs(OUTPUT_PATH)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logging \n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    filename=f\"{OUTPUT_PATH}/log\", \n",
    "                    filemode=\"a+\",\n",
    "                    format=\"%(asctime)s;%(levelname)s;%(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-parish",
   "metadata": {},
   "source": [
    "# Build Embedding \n",
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the data contained directory/file \n",
    "UD_English_EWT = \"../../UD_English-EWT-master/corpus\"\n",
    "# UD_English_EWT =  \"../../UD_English-EWT-master/corpus/en_ewt-ud-train.conllu\"\n",
    "# WIKI = \"../../wikipedia_data/treebank.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Corpus path: {UD_English_EWT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-nicholas",
   "metadata": {},
   "source": [
    "NOTE: When loading dataset to `Corpus`, set `ignore_punctuation` to `False` if `DependencyContext` is used to build co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = mangoes.Corpus(UD_English_EWT, \n",
    "                        reader=mangoes.corpus.CONLLU, \n",
    "                        language=\"English\",\n",
    "                        lower=True, \n",
    "                        ignore_punctuation=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Corpus has {} sentences, {} words, {} unique tokens\".format(corpus.nb_sentences, corpus.size, len(corpus.words_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-australia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save corpus \n",
    "corpus_metadata = os.path.join(OUTPUT_PATH, \".corpus\")\n",
    "print(\"Saved Corpus\")\n",
    "corpus.save_metadata(corpus_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load \n",
    "# corpus = mangoes.Corpus.load_from_metadata(corpus_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-solomon",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "#### -- Target Words --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Building target words...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_filter_lemma = mangoes.corpus.remove_elements(nltk.corpus.stopwords.words('english'), attribute=\"lemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_filter = mangoes.corpus.remove_elements(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-saturn",
   "metadata": {},
   "source": [
    "#### Option 1: Use Lemma and POS as targetwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_vocabulary = corpus.create_vocabulary(attributes=(\"lemma\",\"POS\"), \n",
    "                                              filters = [ stopwords_filter_lemma,  # removes stopwords \n",
    "                                                         mangoes.corpus.remove_most_frequent(100), # removes words that are frequent more than 100\n",
    "                                                         mangoes.corpus.remove_least_frequent(2)]) # removes words that are frequent less than 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-stuff",
   "metadata": {},
   "source": [
    "#### Option 2: Only keep lemma as targetwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_vocabulary = corpus.create_vocabulary(attributes=\"lemma\", \n",
    "#                                               filters = [ stopwords_filter, \n",
    "#                                                          mangoes.corpus.remove_most_frequent(100),\n",
    "#                                                          mangoes.corpus.remove_least_frequent(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-potter",
   "metadata": {},
   "source": [
    "#### Option 3: Use Lemma and POS as targetwords + keep only POS of \"NOUN\", \"VERB\", \"ADJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_filter_target = mangoes.corpus.filter_by_attribute(\"POS\", [\"NOUN\", \"VERB\", \"ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must include POS as one of attributes if POS filter is used\n",
    "# target_vocabulary = corpus.create_vocabulary(attributes=(\"lemma\",\"POS\"), \n",
    "#                                             filters = [ stopwords_filter_lemma, \n",
    "#                                                         pos_filter_target,\n",
    "#                                                         mangoes.corpus.remove_most_frequent(100),\n",
    "#                                                         mangoes.corpus.remove_least_frequent(2)],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-gazette",
   "metadata": {},
   "source": [
    "#### Check target vocaulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(target_vocabulary)} words will be used as target vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Target Words: {len(target_vocabulary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the target vocabulary\n",
    "target_vocabulary._index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-wayne",
   "metadata": {},
   "source": [
    "#### -- Context Words --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Building Context words...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-spiritual",
   "metadata": {},
   "source": [
    "#### Option 1: Only keep lemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vocabulary = corpus.create_vocabulary(attributes=(\"lemma\"), \n",
    "                                              filters = [ stopwords_filter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-latest",
   "metadata": {},
   "source": [
    "#### Option 2: Keep lemma and POS with \"VERB\" or \"ADJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_filter_context = mangoes.corpus.filter_by_attribute(\"POS\",[\"NOUN\", \"VERB\", \"ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context_vocabulary = corpus.create_vocabulary(attributes=(\"lemma\",\"POS\"), \n",
    "#                                             filters = [ stopwords_filter_lemma,\n",
    "#                                                         pos_filter_context])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-recycling",
   "metadata": {},
   "source": [
    "#### Check context vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(context_vocabulary)} words will be used as target vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f\"Context words: {len(context_vocabulary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vocabulary._index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-implement",
   "metadata": {},
   "source": [
    "### Context "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-public",
   "metadata": {},
   "source": [
    "#### Option 1: consider dependency relation  as undirected by setting directed parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: entity needs to match with context_vocabulary \n",
    "dependency_context = mangoes.context.DependencyBasedContext(entity=(\"lemma\"), \n",
    "                                                            labels=True,\n",
    "                                                            collapse=True, \n",
    "                                                            vocabulary=context_vocabulary,\n",
    "                                                            directed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-harassment",
   "metadata": {},
   "source": [
    "#### Option 2: consider only dependency relation of \"advmod\" or \"nsubj\"\n",
    "Note if collapse is set to True, then case will be included as well. \n",
    "\n",
    "\n",
    "This will result in changed number of context words when co-occurrence matrix is built "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency_context = mangoes.context.DependencyBasedContext(entity=(\"lemma\",\"POS\"), \n",
    "#                                                             labels=True,\n",
    "#                                                             collapse=True, \n",
    "#                                                             vocabulary=context_vocabulary,\n",
    "#                                                             deprel_keep = (\"advmod\", \"nsubj\"),\n",
    "#                                                             directed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-yield",
   "metadata": {},
   "source": [
    "#### Option 3 adding depth to consider indirected dependency relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency_context = mangoes.context.DependencyBasedContext(entity=(\"lemma\",\"POS\"), \n",
    "#                                                             labels=True,\n",
    "#                                                             collapse=True, \n",
    "#                                                             vocabulary=context_vocabulary,\n",
    "#                                                             directed=False,\n",
    "#                                                             depth=2\n",
    "#                                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-headline",
   "metadata": {},
   "source": [
    "#### Option 4: Combining option 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-gazette",
   "metadata": {},
   "source": [
    "If `depth` > 1 and `deprel_keep` is specified then `deprel_keep` will be counted as long as indirected dependency relations has one relation from `deprel_keep`.\n",
    "\n",
    "\n",
    "eg. If `depth=2` and `deprel_keep=(\"nsubj\")` then  `{'lemma': 'muslim', 'POS': 'ADJ'}/nsubj_amod\",` will be included as context words since one of the dependency relation `nsubj` is in `deprel_keep`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency_context = mangoes.context.DependencyBasedContext(entity=(\"lemma\",\"POS\"), \n",
    "#                                                             labels=True,\n",
    "#                                                             collapse=True, \n",
    "#                                                             vocabulary=context_vocabulary,\n",
    "#                                                             directed=False,\n",
    "#                                                             deprel_keep=(\"advmod\", \"nsubj\"),\n",
    "#                                                             depth=2\n",
    "#                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save vocabularies \n",
    "target_vocabulary_file_name = \"vocabulary_{}_target_words\".format(len(target_vocabulary))\n",
    "context_vocabulary_file_name = \"vocabulary_{}_context_words\".format(len(context_vocabulary))\n",
    "\n",
    "# # or load by specify saved vocabulary files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-cardiff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # save\n",
    "target_vocabulary.save(OUTPUT_PATH, name=target_vocabulary_file_name)\n",
    "context_vocabulary.save(OUTPUT_PATH, name=context_vocabulary_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabs\n",
    "# target_vocabulary = mangoes.Vocabulary.load(\"output\", target_vocabulary_file_name)\n",
    "# context_vocabulary = mangoes.Vocabulary.load(\"output\", context_vocabulary_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-melissa",
   "metadata": {},
   "source": [
    "### Cooccurrence Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-massachusetts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coocc_count = mangoes.counting.count_cooccurrence(corpus,  \n",
    "                                                target_vocabulary, \n",
    "                                                context=dependency_context,\n",
    "                                                )\n",
    "\n",
    "coocc_count.pprint(display=display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"target words\")\n",
    "coocc_count.words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"context words\")\n",
    "coocc_count.contexts_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "coocc_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-vampire",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 11\n",
    "print(\"target word: \", target_vocabulary[i])\n",
    "print(\"close words\")\n",
    "pprint.pprint(coocc_count.get_closest_words(target_vocabulary[i], 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-allocation",
   "metadata": {},
   "source": [
    "### Weighting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmi = mangoes.weighting.PPMI()\n",
    "svd = mangoes.reduction.SVD(dimensions=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = mangoes.create_representation(coocc_count, weighting=ppmi, reduction=svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-renewal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embeddings.pprint(display=display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the embeddings \n",
    "embedding_path = os.path.join(OUTPUT_PATH,\n",
    "                              \"embeddings/ppmi_svd_{}target_words_deprel\".format(len(target_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.save(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding \n",
    "# embeddings = mangoes.Embeddings.load(embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-adolescent",
   "metadata": {},
   "source": [
    "# Explore Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-section",
   "metadata": {},
   "source": [
    "### Closest Words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-oxide",
   "metadata": {},
   "source": [
    "#### Similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = {0: \"cityblock\",\n",
    "        1: \"cosine\", \n",
    "        2: \"euclidean\", \n",
    "        3: \"l1\", \n",
    "        4:\"l2\", \n",
    "        5:\"manhattan\",\n",
    "        6:\"braycurtis\", \n",
    "        7:\"canberra\", \n",
    "        8:\"chebyshev\", \n",
    "        9:\"correlation\", \n",
    "        10:\"dice\", \n",
    "        11:\"hamming\", \n",
    "        12:\"jaccard\", \n",
    "        13:\"kulsinski\", \n",
    "        14:\"mahalanobis\", \n",
    "       15: \"minkowski\", \n",
    "       16: \"rogerstanimoto\", \n",
    "       17: \"russellrao\", \n",
    "       18: \"seuclidean\", \n",
    "        19:\"sokalmichener\", \n",
    "        20:\"sokalsneath\", \n",
    "       21: \"sqeuclidean\", \n",
    "       22: \"yule\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "nb = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-discretion",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = {word: pd.Series([w for w, _ in embeddings.get_closest_words(word, nb=nb, metric=sims[i])], index=range(1,nb+1))\n",
    "          for word in embeddings.words[100:200:10]}\n",
    "print(f\"similarity measure: {sims[i]}\")\n",
    "print(pd.DataFrame(result).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-indiana",
   "metadata": {},
   "source": [
    "### Analogies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what words are available \n",
    "question = \"king queen male\"\n",
    "ans = \"female\"\n",
    "for w in (question.split() + [ans]):\n",
    "    try:\n",
    "        embeddings.words.word_index[w]\n",
    "        print(f\"'{w}' exists\")\n",
    "    except KeyError:\n",
    "        print(f\"'{w}'  doesn't exist in embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can resolve analogy according to a representation using the analogy() method\n",
    "# Here, we will display the results of some examples :\n",
    "for analogy in [question]:\n",
    "    print(analogy, '->', embeddings.analogy(analogy,5).using_cosadd)\n",
    "    print(analogy, '->', embeddings.analogy(analogy,5).using_cosmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-catch",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import mangoes.visualize\n",
    "plt.figure()\n",
    "\n",
    "# 1. distances between the words\n",
    "ax = plt.subplot(221, projection='polar')\n",
    "mangoes.visualize.plot_distances(embeddings, ax)\n",
    "\n",
    "# 2. isotropy\n",
    "ax = plt.subplot(222)\n",
    "mangoes.visualize.plot_isotropy(embeddings, ax)\n",
    "\n",
    "# 3. t-sne\n",
    "plt.subplot(212)\n",
    "mangoes.visualize.plot_tsne(embeddings)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-cheese",
   "metadata": {},
   "source": [
    "# Evalutaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-instrumentation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Evaluate\n",
    "import mangoes.evaluation.analogy\n",
    "\n",
    "google_dataset = mangoes.evaluation.analogy.GOOGLE\n",
    "msr_dataset = mangoes.evaluation.analogy.MSR\n",
    "\n",
    "analogy_evaluation = mangoes.evaluation.analogy.Evaluation(embeddings, google_dataset, msr_dataset)\n",
    "print(analogy_evaluation.get_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-figure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:namre_dev] *",
   "language": "python",
   "name": "conda-env-namre_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
