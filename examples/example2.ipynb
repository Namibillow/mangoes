{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gentle-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import mangoes\n",
    "import nltk\n",
    "import string \n",
    "import pprint \n",
    "import os \n",
    "import datetime "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-enzyme",
   "metadata": {},
   "source": [
    "Read more for \n",
    "\n",
    "https://github.com/UniversalDependencies/UD_English-EWT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interested-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brilliant-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or specify date to saved ones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "useful-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = os.path.join(os.path.abspath(''), \"output/{}\".format(date))\n",
    "# if not os.path.exists(OUTPUT_PATH):\n",
    "#     print(\"made a dir: \", OUTPUT_PATH)\n",
    "#     os.makedirs(OUTPUT_PATH)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "editorial-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-03-16-23-12'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-parish",
   "metadata": {},
   "source": [
    "# Build Embedding \n",
    "### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confirmed-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "UD_English_EWT = \"../../UD_English-EWT-master/corpus\"\n",
    "# UD_English_EWT =  \"../../UD_English-EWT-master/corpus/en_ewt-ud-train.conllu\"\n",
    "# WIKI = \"../../wikipedia_data/treebank.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "charitable-spray",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fe64818a1846e7b719c232faf9d633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Counting words: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus = mangoes.Corpus(UD_English_EWT, \n",
    "                        reader=mangoes.corpus.CONLLU, \n",
    "                        language=\"English\",\n",
    "                        lower=True, \n",
    "                        ignore_punctuation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecological-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29887 sentences, 615697 words\n"
     ]
    }
   ],
   "source": [
    "print(\"{} sentences, {} words\".format(corpus.nb_sentences, corpus.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "retired-australia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ../../UD_English-EWT-master/corpus\n",
      "Language: English\n",
      "Reader: <class 'mangoes.utils.reader.ConllUSentenceGenerator'>\n",
      "Parameters:\n",
      "\t- lower : True\n",
      "\t- digit : False\n",
      "\t- ignore_punctuation : False\n",
      "Size:\n",
      "\t- sentences: 29887\n",
      "\t- total number of tokens: 615697\n",
      "\t- number of unique tokens: 48789\n"
     ]
    }
   ],
   "source": [
    "corpus.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chief-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save corpus \n",
    "# corpus_metadata = os.path.join(OUTPUT_PATH, \".corpus\")\n",
    "# print(\"Saved Corpus\")\n",
    "# corpus.save_metadata(corpus_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unsigned-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or load \n",
    "# corpus = mangoes.Corpus.load_from_metadata(corpus_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-solomon",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "#### -- Target Words --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alike-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_filter_lemma = mangoes.corpus.remove_elements(nltk.corpus.stopwords.words('english'), attribute=\"lemma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-saturn",
   "metadata": {},
   "source": [
    "#### Option 1: Use Lemma and POS as targetwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "checked-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_vocabulary = corpus.create_vocabulary(attributes=(\"lemma\",\"POS\"), \n",
    "#                                               filters = [ stopwords_filter_lemma, \n",
    "#                                                          mangoes.corpus.remove_most_frequent(100),\n",
    "#                                                          mangoes.corpus.remove_least_frequent(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-stuff",
   "metadata": {},
   "source": [
    "#### Option 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "maritime-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option for only keeping lemma \n",
    "stopwords_filter = mangoes.corpus.remove_elements(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pursuant-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_vocabulary = corpus.create_vocabulary(attributes=\"lemma\", \n",
    "#                                               filters = [ stopwords_filter, \n",
    "#                                                          mangoes.corpus.remove_most_frequent(100),\n",
    "#                                                          mangoes.corpus.remove_least_frequent(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-potter",
   "metadata": {},
   "source": [
    "#### Option 3: Use Lemma and POS as targetwords + keep only POS of \"NOUN\", \"VERB\", \"ADJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precious-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_filter_target = mangoes.corpus.filter_by_attribute(\"POS\", [\"NOUN\", \"VERB\", \"ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "going-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must include POS as one of attributes if POS filter is used\n",
    "target_vocabulary = corpus.create_vocabulary(attributes=(\"lemma\",\"POS\"), \n",
    "                                            filters = [ stopwords_filter_lemma, \n",
    "                                                        pos_filter_target,\n",
    "                                                        mangoes.corpus.remove_most_frequent(100),\n",
    "                                                        mangoes.corpus.remove_least_frequent(2)],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-gazette",
   "metadata": {},
   "source": [
    "#### Check target vocaulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ranging-washington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11077 words will be used as target vocabulary\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(target_vocabulary)} words will be used as target vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unlikely-hobby",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(lemma='story', POS='NOUN'),\n",
       " Token(lemma='attack', POS='NOUN'),\n",
       " Token(lemma='social', POS='ADJ'),\n",
       " Token(lemma='bad', POS='ADJ'),\n",
       " Token(lemma='market', POS='NOUN'),\n",
       " Token(lemma='house', POS='NOUN'),\n",
       " Token(lemma='territory', POS='NOUN'),\n",
       " Token(lemma='original', POS='ADJ'),\n",
       " Token(lemma='claim', POS='VERB'),\n",
       " Token(lemma='style', POS='NOUN'),\n",
       " Token(lemma='horse', POS='NOUN'),\n",
       " Token(lemma='text', POS='NOUN'),\n",
       " Token(lemma='western', POS='ADJ'),\n",
       " Token(lemma='decision', POS='NOUN'),\n",
       " Token(lemma='true', POS='ADJ'),\n",
       " Token(lemma='friendly', POS='ADJ'),\n",
       " Token(lemma='file', POS='NOUN'),\n",
       " Token(lemma='choose', POS='VERB'),\n",
       " Token(lemma='discuss', POS='VERB'),\n",
       " Token(lemma='mention', POS='VERB'),\n",
       " Token(lemma='propose', POS='VERB'),\n",
       " Token(lemma='excellent', POS='ADJ'),\n",
       " Token(lemma='surface', POS='NOUN'),\n",
       " Token(lemma='popular', POS='ADJ'),\n",
       " Token(lemma='expect', POS='VERB'),\n",
       " Token(lemma='happen', POS='VERB'),\n",
       " Token(lemma='german', POS='ADJ'),\n",
       " Token(lemma='object', POS='NOUN'),\n",
       " Token(lemma='troops', POS='NOUN'),\n",
       " Token(lemma='young', POS='ADJ'),\n",
       " Token(lemma='introduce', POS='VERB'),\n",
       " Token(lemma='dog', POS='NOUN'),\n",
       " Token(lemma='director', POS='NOUN'),\n",
       " Token(lemma='decide', POS='VERB'),\n",
       " Token(lemma='unit', POS='NOUN'),\n",
       " Token(lemma='check', POS='VERB'),\n",
       " Token(lemma='science', POS='NOUN'),\n",
       " Token(lemma='cost', POS='NOUN'),\n",
       " Token(lemma='wait', POS='VERB'),\n",
       " Token(lemma='sea', POS='NOUN'),\n",
       " Token(lemma='solution', POS='NOUN'),\n",
       " Token(lemma='effort', POS='NOUN'),\n",
       " Token(lemma='join', POS='VERB'),\n",
       " Token(lemma='movement', POS='NOUN'),\n",
       " Token(lemma='enter', POS='VERB'),\n",
       " Token(lemma='note', POS='VERB'),\n",
       " Token(lemma='stage', POS='NOUN'),\n",
       " Token(lemma='significant', POS='ADJ'),\n",
       " Token(lemma='application', POS='NOUN'),\n",
       " Token(lemma='atomic', POS='ADJ'),\n",
       " Token(lemma='plan', POS='NOUN'),\n",
       " Token(lemma='drive', POS='VERB'),\n",
       " Token(lemma='appeal', POS='NOUN'),\n",
       " Token(lemma='spend', POS='VERB'),\n",
       " Token(lemma='enjoy', POS='VERB'),\n",
       " Token(lemma='understand', POS='VERB'),\n",
       " Token(lemma='mass', POS='NOUN'),\n",
       " Token(lemma='health', POS='NOUN'),\n",
       " Token(lemma='restaurant', POS='NOUN'),\n",
       " Token(lemma='egg', POS='NOUN'),\n",
       " Token(lemma='engine', POS='NOUN'),\n",
       " Token(lemma='support', POS='NOUN'),\n",
       " Token(lemma='bit', POS='NOUN'),\n",
       " Token(lemma='media', POS='NOUN'),\n",
       " Token(lemma='fall', POS='VERB'),\n",
       " Token(lemma='subject', POS='NOUN'),\n",
       " Token(lemma='reduce', POS='VERB'),\n",
       " Token(lemma='store', POS='NOUN'),\n",
       " Token(lemma='carry', POS='VERB'),\n",
       " Token(lemma='third', POS='ADJ'),\n",
       " Token(lemma='indicate', POS='VERB'),\n",
       " Token(lemma='rule', POS='NOUN'),\n",
       " Token(lemma='care', POS='NOUN'),\n",
       " Token(lemma='activity', POS='NOUN'),\n",
       " Token(lemma='technique', POS='NOUN'),\n",
       " Token(lemma='province', POS='NOUN'),\n",
       " Token(lemma='method', POS='NOUN'),\n",
       " Token(lemma='article', POS='NOUN'),\n",
       " Token(lemma='higher', POS='ADJ'),\n",
       " Token(lemma='material', POS='NOUN'),\n",
       " Token(lemma='father', POS='NOUN'),\n",
       " Token(lemma='replace', POS='VERB'),\n",
       " Token(lemma='charge', POS='VERB'),\n",
       " Token(lemma='argue', POS='VERB'),\n",
       " Token(lemma='organization', POS='NOUN'),\n",
       " Token(lemma='variety', POS='NOUN'),\n",
       " Token(lemma='plan', POS='VERB'),\n",
       " Token(lemma='evidence', POS='NOUN'),\n",
       " Token(lemma='agree', POS='VERB'),\n",
       " Token(lemma='fight', POS='VERB'),\n",
       " Token(lemma='explain', POS='VERB'),\n",
       " Token(lemma='town', POS='NOUN'),\n",
       " Token(lemma='basis', POS='NOUN'),\n",
       " Token(lemma='discover', POS='VERB'),\n",
       " Token(lemma='apply', POS='VERB'),\n",
       " Token(lemma='treat', POS='VERB'),\n",
       " Token(lemma='view', POS='NOUN'),\n",
       " Token(lemma='alkali', POS='ADJ'),\n",
       " Token(lemma='big', POS='ADJ'),\n",
       " Token(lemma='response', POS='NOUN'),\n",
       " Token(lemma='wife', POS='NOUN'),\n",
       " Token(lemma='southern', POS='ADJ'),\n",
       " Token(lemma='present', POS='ADJ'),\n",
       " Token(lemma='rights', POS='NOUN'),\n",
       " Token(lemma='tax', POS='NOUN'),\n",
       " Token(lemma='condition', POS='NOUN'),\n",
       " Token(lemma='associate', POS='VERB'),\n",
       " Token(lemma='temperature', POS='NOUN'),\n",
       " Token(lemma='nation', POS='NOUN'),\n",
       " Token(lemma='defeat', POS='VERB'),\n",
       " Token(lemma='open', POS='VERB'),\n",
       " Token(lemma='nuclear', POS='ADJ'),\n",
       " Token(lemma='right', POS='ADJ'),\n",
       " Token(lemma='recent', POS='ADJ'),\n",
       " Token(lemma='addition', POS='NOUN'),\n",
       " Token(lemma='perform', POS='VERB'),\n",
       " Token(lemma='learn', POS='VERB'),\n",
       " Token(lemma='cover', POS='VERB'),\n",
       " Token(lemma='magnitude', POS='NOUN'),\n",
       " Token(lemma='confederate', POS='ADJ'),\n",
       " Token(lemma='nucleus', POS='NOUN'),\n",
       " Token(lemma='low', POS='ADJ'),\n",
       " Token(lemma='stop', POS='VERB'),\n",
       " Token(lemma='charge', POS='NOUN'),\n",
       " Token(lemma='professional', POS='ADJ'),\n",
       " Token(lemma='standard', POS='NOUN'),\n",
       " Token(lemma='animation', POS='NOUN'),\n",
       " Token(lemma='research', POS='NOUN'),\n",
       " Token(lemma='operation', POS='NOUN'),\n",
       " Token(lemma='message', POS='NOUN'),\n",
       " Token(lemma='whole', POS='ADJ'),\n",
       " Token(lemma='option', POS='NOUN'),\n",
       " Token(lemma='meaning', POS='NOUN'),\n",
       " Token(lemma='larger', POS='ADJ'),\n",
       " Token(lemma='policy', POS='NOUN'),\n",
       " Token(lemma='french', POS='ADJ'),\n",
       " Token(lemma='risk', POS='NOUN'),\n",
       " Token(lemma='capital', POS='NOUN'),\n",
       " Token(lemma='range', POS='NOUN'),\n",
       " Token(lemma='seek', POS='VERB'),\n",
       " Token(lemma='link', POS='NOUN'),\n",
       " Token(lemma='statement', POS='NOUN'),\n",
       " Token(lemma='involve', POS='VERB'),\n",
       " Token(lemma='central', POS='ADJ'),\n",
       " Token(lemma='half', POS='NOUN'),\n",
       " Token(lemma='black', POS='ADJ'),\n",
       " Token(lemma='ion', POS='NOUN'),\n",
       " Token(lemma='peace', POS='NOUN'),\n",
       " Token(lemma='self', POS='NOUN'),\n",
       " Token(lemma='cell', POS='NOUN'),\n",
       " Token(lemma='size', POS='NOUN'),\n",
       " Token(lemma='top', POS='ADJ'),\n",
       " Token(lemma='couple', POS='NOUN'),\n",
       " Token(lemma='economic', POS='ADJ'),\n",
       " Token(lemma='student', POS='NOUN'),\n",
       " Token(lemma='sign', POS='VERB'),\n",
       " Token(lemma='function', POS='NOUN'),\n",
       " Token(lemma='percentage', POS='NOUN'),\n",
       " Token(lemma='reaction', POS='NOUN'),\n",
       " Token(lemma='entire', POS='ADJ'),\n",
       " Token(lemma='girl', POS='NOUN'),\n",
       " Token(lemma='treatment', POS='NOUN'),\n",
       " Token(lemma='test', POS='NOUN'),\n",
       " Token(lemma='white', POS='ADJ'),\n",
       " Token(lemma='economy', POS='NOUN'),\n",
       " Token(lemma='maintain', POS='VERB'),\n",
       " Token(lemma='derive', POS='VERB'),\n",
       " Token(lemma='present', POS='VERB'),\n",
       " Token(lemma='relate', POS='VERB'),\n",
       " Token(lemma='user', POS='NOUN'),\n",
       " Token(lemma='base', POS='NOUN'),\n",
       " Token(lemma='role', POS='NOUN'),\n",
       " Token(lemma='order', POS='VERB'),\n",
       " Token(lemma='ship', POS='NOUN'),\n",
       " Token(lemma='particle', POS='NOUN'),\n",
       " Token(lemma='raise', POS='VERB'),\n",
       " Token(lemma='kind', POS='NOUN'),\n",
       " Token(lemma='mother', POS='NOUN'),\n",
       " Token(lemma='record', POS='NOUN'),\n",
       " Token(lemma='compound', POS='NOUN'),\n",
       " Token(lemma='aluminium', POS='NOUN'),\n",
       " Token(lemma='table', POS='NOUN'),\n",
       " Token(lemma='close', POS='ADJ'),\n",
       " Token(lemma='copy', POS='NOUN'),\n",
       " Token(lemma='fish', POS='NOUN'),\n",
       " Token(lemma='less', POS='ADJ'),\n",
       " Token(lemma='attempt', POS='NOUN'),\n",
       " Token(lemma='egyptian', POS='ADJ'),\n",
       " Token(lemma='parent', POS='NOUN'),\n",
       " Token(lemma='consist', POS='VERB'),\n",
       " Token(lemma='prove', POS='VERB'),\n",
       " Token(lemma='crew', POS='NOUN'),\n",
       " Token(lemma='depend', POS='VERB'),\n",
       " Token(lemma='act', POS='VERB'),\n",
       " Token(lemma='difference', POS='NOUN'),\n",
       " Token(lemma='special', POS='ADJ'),\n",
       " Token(lemma='image', POS='NOUN'),\n",
       " Token(lemma='refuse', POS='VERB'),\n",
       " Token(lemma='global', POS='ADJ'),\n",
       " Token(lemma='industry', POS='NOUN'),\n",
       " Token(lemma='announce', POS='VERB'),\n",
       " Token(lemma='place', POS='VERB'),\n",
       " Token(lemma='picture', POS='NOUN'),\n",
       " Token(lemma='current', POS='ADJ'),\n",
       " Token(lemma='capture', POS='VERB'),\n",
       " Token(lemma='stable', POS='ADJ'),\n",
       " Token(lemma='traditional', POS='ADJ'),\n",
       " Token(lemma='proton', POS='NOUN'),\n",
       " Token(lemma='consonant', POS='NOUN'),\n",
       " Token(lemma='authority', POS='NOUN'),\n",
       " Token(lemma='community', POS='NOUN'),\n",
       " Token(lemma='comment', POS='NOUN'),\n",
       " Token(lemma='japanese', POS='ADJ'),\n",
       " Token(lemma='foreign', POS='ADJ'),\n",
       " Token(lemma='security', POS='NOUN'),\n",
       " Token(lemma='help', POS='NOUN'),\n",
       " Token(lemma='owner', POS='NOUN'),\n",
       " Token(lemma='walk', POS='VERB'),\n",
       " Token(lemma='career', POS='NOUN'),\n",
       " Token(lemma='isotope', POS='NOUN'),\n",
       " Token(lemma='intend', POS='VERB'),\n",
       " Token(lemma='remove', POS='VERB'),\n",
       " Token(lemma='personal', POS='ADJ'),\n",
       " Token(lemma='prepare', POS='VERB'),\n",
       " Token(lemma='aircraft', POS='NOUN'),\n",
       " Token(lemma='practice', POS='NOUN'),\n",
       " Token(lemma='weapon', POS='NOUN'),\n",
       " Token(lemma='feature', POS='NOUN'),\n",
       " Token(lemma='break', POS='VERB'),\n",
       " Token(lemma='situation', POS='NOUN'),\n",
       " Token(lemma='mind', POS='NOUN'),\n",
       " Token(lemma='north', POS='NOUN'),\n",
       " Token(lemma='identify', POS='VERB'),\n",
       " Token(lemma='symbol', POS='NOUN'),\n",
       " Token(lemma='launch', POS='VERB'),\n",
       " Token(lemma='determine', POS='VERB'),\n",
       " Token(lemma='specific', POS='ADJ'),\n",
       " Token(lemma='total', POS='ADJ'),\n",
       " Token(lemma='rest', POS='NOUN'),\n",
       " Token(lemma='compare', POS='VERB'),\n",
       " Token(lemma='medical', POS='ADJ'),\n",
       " Token(lemma='south', POS='NOUN'),\n",
       " Token(lemma='player', POS='NOUN'),\n",
       " Token(lemma='right', POS='NOUN'),\n",
       " Token(lemma='open', POS='ADJ'),\n",
       " Token(lemma='attend', POS='VERB'),\n",
       " Token(lemma='draft', POS='NOUN'),\n",
       " Token(lemma='least', POS='ADJ'),\n",
       " Token(lemma='flight', POS='NOUN'),\n",
       " Token(lemma='website', POS='NOUN'),\n",
       " Token(lemma='hard', POS='ADJ'),\n",
       " Token(lemma='indian', POS='ADJ'),\n",
       " Token(lemma='pair', POS='NOUN'),\n",
       " Token(lemma='federal', POS='ADJ'),\n",
       " Token(lemma='remember', POS='VERB'),\n",
       " Token(lemma='sense', POS='NOUN'),\n",
       " Token(lemma='private', POS='ADJ'),\n",
       " Token(lemma='stand', POS='VERB'),\n",
       " Token(lemma='contract', POS='NOUN'),\n",
       " Token(lemma='president', POS='NOUN'),\n",
       " Token(lemma='matter', POS='NOUN'),\n",
       " Token(lemma='summer', POS='NOUN'),\n",
       " Token(lemma='agent', POS='NOUN'),\n",
       " Token(lemma='travel', POS='VERB'),\n",
       " Token(lemma='arrive', POS='VERB'),\n",
       " Token(lemma='fail', POS='VERB'),\n",
       " Token(lemma='eye', POS='NOUN'),\n",
       " Token(lemma='fix', POS='VERB'),\n",
       " Token(lemma='majority', POS='NOUN'),\n",
       " Token(lemma='match', POS='NOUN'),\n",
       " Token(lemma='relationship', POS='NOUN'),\n",
       " Token(lemma='section', POS='NOUN'),\n",
       " Token(lemma='physical', POS='ADJ'),\n",
       " Token(lemma='else', POS='ADJ'),\n",
       " Token(lemma='civil', POS='ADJ'),\n",
       " Token(lemma='recognize', POS='VERB'),\n",
       " Token(lemma='video', POS='NOUN'),\n",
       " Token(lemma='song', POS='NOUN'),\n",
       " Token(lemma='philosophy', POS='NOUN'),\n",
       " Token(lemma='enough', POS='ADJ'),\n",
       " Token(lemma='religious', POS='ADJ'),\n",
       " Token(lemma='estimate', POS='VERB'),\n",
       " Token(lemma='writer', POS='NOUN'),\n",
       " Token(lemma='administration', POS='NOUN'),\n",
       " Token(lemma='happy', POS='ADJ'),\n",
       " Token(lemma='control', POS='VERB'),\n",
       " Token(lemma='need', POS='NOUN'),\n",
       " Token(lemma='numerous', POS='ADJ'),\n",
       " Token(lemma='hotel', POS='NOUN'),\n",
       " Token(lemma='study', POS='VERB'),\n",
       " Token(lemma='education', POS='NOUN'),\n",
       " Token(lemma='nature', POS='NOUN'),\n",
       " Token(lemma='artist', POS='NOUN'),\n",
       " Token(lemma='figure', POS='NOUN'),\n",
       " Token(lemma='independent', POS='ADJ'),\n",
       " Token(lemma='cultural', POS='ADJ'),\n",
       " Token(lemma='feature', POS='VERB'),\n",
       " Token(lemma='clear', POS='ADJ'),\n",
       " Token(lemma='lack', POS='NOUN'),\n",
       " Token(lemma='hair', POS='NOUN'),\n",
       " Token(lemma='loss', POS='NOUN'),\n",
       " Token(lemma='assume', POS='VERB'),\n",
       " Token(lemma='feed', POS='VERB'),\n",
       " Token(lemma='status', POS='NOUN'),\n",
       " Token(lemma='slavery', POS='NOUN'),\n",
       " Token(lemma='algorithm', POS='NOUN'),\n",
       " Token(lemma='official', POS='NOUN'),\n",
       " Token(lemma='employee', POS='NOUN'),\n",
       " Token(lemma='piece', POS='NOUN'),\n",
       " Token(lemma='love', POS='NOUN'),\n",
       " Token(lemma='back', POS='NOUN'),\n",
       " Token(lemma='detail', POS='NOUN'),\n",
       " Token(lemma='share', POS='VERB'),\n",
       " Token(lemma='bird', POS='NOUN'),\n",
       " Token(lemma='helpful', POS='ADJ'),\n",
       " Token(lemma='poor', POS='ADJ'),\n",
       " Token(lemma='step', POS='NOUN'),\n",
       " Token(lemma='difficult', POS='ADJ'),\n",
       " Token(lemma='sound', POS='NOUN'),\n",
       " Token(lemma='later', POS='ADJ'),\n",
       " Token(lemma='environment', POS='NOUN'),\n",
       " Token(lemma='suffer', POS='VERB'),\n",
       " Token(lemma='morning', POS='NOUN'),\n",
       " Token(lemma='training', POS='NOUN'),\n",
       " Token(lemma='force', POS='VERB'),\n",
       " Token(lemma='color', POS='NOUN'),\n",
       " Token(lemma='tradition', POS='NOUN'),\n",
       " Token(lemma='observe', POS='VERB'),\n",
       " Token(lemma='influence', POS='NOUN'),\n",
       " Token(lemma='society', POS='NOUN'),\n",
       " Token(lemma='greater', POS='ADJ'),\n",
       " Token(lemma='growth', POS='NOUN'),\n",
       " Token(lemma='direct', POS='ADJ'),\n",
       " Token(lemma='clean', POS='ADJ'),\n",
       " Token(lemma='reflect', POS='VERB'),\n",
       " Token(lemma='official', POS='ADJ'),\n",
       " Token(lemma='building', POS='NOUN'),\n",
       " Token(lemma='season', POS='NOUN'),\n",
       " Token(lemma='design', POS='NOUN'),\n",
       " Token(lemma='lunar', POS='ADJ'),\n",
       " Token(lemma='means', POS='NOUN'),\n",
       " Token(lemma='separate', POS='VERB'),\n",
       " Token(lemma='oppose', POS='VERB'),\n",
       " Token(lemma='successful', POS='ADJ'),\n",
       " Token(lemma='simple', POS='ADJ'),\n",
       " Token(lemma='northern', POS='ADJ'),\n",
       " Token(lemma='daughter', POS='NOUN'),\n",
       " Token(lemma='success', POS='NOUN'),\n",
       " Token(lemma='fine', POS='ADJ'),\n",
       " Token(lemma='argument', POS='NOUN'),\n",
       " Token(lemma='credit', POS='NOUN'),\n",
       " Token(lemma='sale', POS='NOUN'),\n",
       " Token(lemma='focus', POS='VERB'),\n",
       " Token(lemma='trial', POS='NOUN'),\n",
       " Token(lemma='band', POS='NOUN'),\n",
       " Token(lemma='king', POS='NOUN'),\n",
       " Token(lemma='record', POS='VERB'),\n",
       " Token(lemma='vary', POS='VERB'),\n",
       " Token(lemma='individual', POS='NOUN'),\n",
       " Token(lemma='dollar', POS='NOUN'),\n",
       " Token(lemma='face', POS='VERB'),\n",
       " Token(lemma='rank', POS='VERB'),\n",
       " Token(lemma='concern', POS='NOUN'),\n",
       " Token(lemma='arm', POS='NOUN'),\n",
       " Token(lemma='degree', POS='NOUN'),\n",
       " Token(lemma='achieve', POS='VERB'),\n",
       " Token(lemma='european', POS='ADJ'),\n",
       " Token(lemma='asteroid', POS='NOUN'),\n",
       " Token(lemma='soldier', POS='NOUN'),\n",
       " Token(lemma='item', POS='NOUN'),\n",
       " Token(lemma='answer', POS='NOUN'),\n",
       " Token(lemma='principle', POS='NOUN'),\n",
       " Token(lemma='handle', POS='VERB'),\n",
       " Token(lemma='prevent', POS='VERB'),\n",
       " Token(lemma='watch', POS='VERB'),\n",
       " Token(lemma='additional', POS='ADJ'),\n",
       " Token(lemma='request', POS='NOUN'),\n",
       " Token(lemma='easy', POS='ADJ'),\n",
       " Token(lemma='account', POS='NOUN'),\n",
       " Token(lemma='smaller', POS='ADJ'),\n",
       " Token(lemma='god', POS='NOUN'),\n",
       " Token(lemma='separate', POS='ADJ'),\n",
       " Token(lemma='collection', POS='NOUN'),\n",
       " Token(lemma='combine', POS='VERB'),\n",
       " Token(lemma='mission', POS='NOUN'),\n",
       " Token(lemma='factor', POS='NOUN'),\n",
       " Token(lemma='datum', POS='NOUN'),\n",
       " Token(lemma='attack', POS='VERB'),\n",
       " Token(lemma='connection', POS='NOUN'),\n",
       " Token(lemma='express', POS='VERB'),\n",
       " Token(lemma='direction', POS='NOUN'),\n",
       " Token(lemma='interested', POS='ADJ'),\n",
       " Token(lemma='regards', POS='NOUN'),\n",
       " Token(lemma='purpose', POS='NOUN'),\n",
       " Token(lemma='page', POS='NOUN'),\n",
       " Token(lemma='code', POS='NOUN'),\n",
       " Token(lemma='doctor', POS='NOUN'),\n",
       " Token(lemma='religion', POS='NOUN'),\n",
       " Token(lemma='leg', POS='NOUN'),\n",
       " Token(lemma='beginning', POS='NOUN'),\n",
       " Token(lemma='birth', POS='NOUN'),\n",
       " Token(lemma='arsenic', POS='NOUN'),\n",
       " Token(lemma='agricultural', POS='ADJ'),\n",
       " Token(lemma='opinion', POS='NOUN'),\n",
       " Token(lemma='conflict', POS='NOUN'),\n",
       " Token(lemma='conference', POS='NOUN'),\n",
       " Token(lemma='chemical', POS='ADJ'),\n",
       " Token(lemma='scale', POS='NOUN'),\n",
       " Token(lemma='deal', POS='VERB'),\n",
       " Token(lemma='officer', POS='NOUN'),\n",
       " Token(lemma='destroy', POS='VERB'),\n",
       " Token(lemma='human', POS='NOUN'),\n",
       " Token(lemma='complete', POS='VERB'),\n",
       " Token(lemma='declare', POS='VERB'),\n",
       " Token(lemma='tank', POS='NOUN'),\n",
       " Token(lemma='divide', POS='VERB'),\n",
       " Token(lemma='branch', POS='NOUN'),\n",
       " Token(lemma='scholar', POS='NOUN'),\n",
       " Token(lemma='slave', POS='NOUN'),\n",
       " Token(lemma='river', POS='NOUN'),\n",
       " Token(lemma='orbit', POS='NOUN'),\n",
       " Token(lemma='sodium', POS='NOUN'),\n",
       " Token(lemma='goal', POS='NOUN'),\n",
       " Token(lemma='fill', POS='VERB'),\n",
       " Token(lemma='effective', POS='ADJ'),\n",
       " Token(lemma='dead', POS='ADJ'),\n",
       " Token(lemma='confirm', POS='VERB'),\n",
       " Token(lemma='sit', POS='VERB'),\n",
       " Token(lemma='necessary', POS='ADJ'),\n",
       " Token(lemma='front', POS='NOUN'),\n",
       " Token(lemma='attention', POS='NOUN'),\n",
       " Token(lemma='kid', POS='NOUN'),\n",
       " Token(lemma='react', POS='VERB'),\n",
       " Token(lemma='attempt', POS='VERB'),\n",
       " Token(lemma='border', POS='NOUN'),\n",
       " Token(lemma='amazing', POS='ADJ'),\n",
       " Token(lemma='save', POS='VERB'),\n",
       " Token(lemma='decade', POS='NOUN'),\n",
       " Token(lemma='presence', POS='NOUN'),\n",
       " Token(lemma='division', POS='NOUN'),\n",
       " Token(lemma='draw', POS='VERB'),\n",
       " Token(lemma='chinese', POS='ADJ'),\n",
       " Token(lemma='generation', POS='NOUN'),\n",
       " Token(lemma='victory', POS='NOUN'),\n",
       " Token(lemma='obtain', POS='VERB'),\n",
       " Token(lemma='climate', POS='NOUN'),\n",
       " Token(lemma='arabic', POS='ADJ'),\n",
       " Token(lemma='astronomer', POS='NOUN'),\n",
       " Token(lemma='close', POS='VERB'),\n",
       " Token(lemma='survive', POS='VERB'),\n",
       " Token(lemma='extend', POS='VERB'),\n",
       " Token(lemma='access', POS='NOUN'),\n",
       " Token(lemma='review', POS='VERB'),\n",
       " Token(lemma='fly', POS='VERB'),\n",
       " Token(lemma='military', POS='NOUN'),\n",
       " Token(lemma='average', POS='ADJ'),\n",
       " Token(lemma='foot', POS='NOUN'),\n",
       " Token(lemma='door', POS='NOUN'),\n",
       " Token(lemma='purchase', POS='VERB'),\n",
       " Token(lemma='worker', POS='NOUN'),\n",
       " Token(lemma='ground', POS='NOUN'),\n",
       " Token(lemma='dialect', POS='NOUN'),\n",
       " Token(lemma='found', POS='VERB'),\n",
       " Token(lemma='board', POS='NOUN'),\n",
       " Token(lemma='top', POS='NOUN'),\n",
       " Token(lemma='movie', POS='NOUN'),\n",
       " Token(lemma='address', POS='NOUN'),\n",
       " Token(lemma='highest', POS='ADJ'),\n",
       " Token(lemma='news', POS='NOUN'),\n",
       " Token(lemma='date', POS='VERB'),\n",
       " Token(lemma='sign', POS='NOUN'),\n",
       " Token(lemma='standard', POS='ADJ'),\n",
       " Token(lemma='wonderful', POS='ADJ'),\n",
       " Token(lemma='definition', POS='NOUN'),\n",
       " Token(lemma='university', POS='NOUN'),\n",
       " Token(lemma='planet', POS='NOUN'),\n",
       " Token(lemma='east', POS='NOUN'),\n",
       " Token(lemma='course', POS='NOUN'),\n",
       " Token(lemma='hydrogen', POS='NOUN'),\n",
       " Token(lemma='neutron', POS='NOUN'),\n",
       " Token(lemma='police', POS='NOUN'),\n",
       " Token(lemma='chance', POS='NOUN'),\n",
       " Token(lemma='thought', POS='NOUN'),\n",
       " Token(lemma='opportunity', POS='NOUN'),\n",
       " Token(lemma='knowledge', POS='NOUN'),\n",
       " Token(lemma='weekend', POS='NOUN'),\n",
       " Token(lemma='e-mail', POS='NOUN'),\n",
       " Token(lemma='compose', POS='VERB'),\n",
       " Token(lemma='fax', POS='NOUN'),\n",
       " Token(lemma='approve', POS='VERB'),\n",
       " Token(lemma='drop', POS='VERB'),\n",
       " Token(lemma='center', POS='NOUN'),\n",
       " Token(lemma='coast', POS='NOUN'),\n",
       " Token(lemma='return', POS='NOUN'),\n",
       " Token(lemma='astronaut', POS='NOUN'),\n",
       " Token(lemma='famous', POS='ADJ'),\n",
       " Token(lemma='cage', POS='NOUN'),\n",
       " Token(lemma='lay', POS='VERB'),\n",
       " Token(lemma='avoid', POS='VERB'),\n",
       " Token(lemma='direct', POS='VERB'),\n",
       " Token(lemma='settlement', POS='NOUN'),\n",
       " Token(lemma='russian', POS='ADJ'),\n",
       " Token(lemma='circle', POS='NOUN'),\n",
       " Token(lemma='constitution', POS='NOUN'),\n",
       " Token(lemma='decay', POS='NOUN'),\n",
       " Token(lemma='astatine', POS='NOUN'),\n",
       " Token(lemma='root', POS='NOUN'),\n",
       " Token(lemma='post', POS='VERB'),\n",
       " Token(lemma='dinner', POS='NOUN'),\n",
       " Token(lemma='trip', POS='NOUN'),\n",
       " Token(lemma='last', POS='VERB'),\n",
       " Token(lemma='west', POS='NOUN'),\n",
       " Token(lemma='expand', POS='VERB'),\n",
       " Token(lemma='participate', POS='VERB'),\n",
       " Token(lemma='threat', POS='NOUN'),\n",
       " Token(lemma='related', POS='ADJ'),\n",
       " Token(lemma='disease', POS='NOUN'),\n",
       " Token(lemma='award', POS='NOUN'),\n",
       " Token(lemma='19th', POS='ADJ'),\n",
       " Token(lemma='independence', POS='NOUN'),\n",
       " Token(lemma='likely', POS='ADJ'),\n",
       " Token(lemma='protect', POS='VERB'),\n",
       " Token(lemma='internet', POS='NOUN'),\n",
       " Token(lemma='governor', POS='NOUN'),\n",
       " Token(lemma='influence', POS='VERB'),\n",
       " Token(lemma='contact', POS='NOUN'),\n",
       " Token(lemma='winter', POS='NOUN'),\n",
       " Token(lemma='paper', POS='NOUN'),\n",
       " Token(lemma='document', POS='NOUN'),\n",
       " Token(lemma='weight', POS='NOUN'),\n",
       " Token(lemma='facility', POS='NOUN'),\n",
       " Token(lemma='screen', POS='NOUN'),\n",
       " Token(lemma='expensive', POS='ADJ'),\n",
       " Token(lemma='mouth', POS='NOUN'),\n",
       " Token(lemma='relation', POS='NOUN'),\n",
       " Token(lemma='concept', POS='NOUN'),\n",
       " Token(lemma='previous', POS='ADJ'),\n",
       " Token(lemma='internal', POS='ADJ'),\n",
       " Token(lemma='primary', POS='ADJ'),\n",
       " Token(lemma='appellate', POS='ADJ'),\n",
       " Token(lemma='eastern', POS='ADJ'),\n",
       " Token(lemma='act', POS='NOUN'),\n",
       " Token(lemma='bus', POS='NOUN'),\n",
       " Token(lemma='elect', POS='VERB'),\n",
       " Token(lemma='note', POS='NOUN'),\n",
       " Token(lemma='financial', POS='ADJ'),\n",
       " Token(lemma='cut', POS='VERB'),\n",
       " Token(lemma='prior', POS='ADJ'),\n",
       " Token(lemma='round', POS='NOUN'),\n",
       " Token(lemma='pick', POS='VERB'),\n",
       " Token(lemma='male', POS='NOUN'),\n",
       " Token(lemma='vote', POS='VERB'),\n",
       " Token(lemma='blood', POS='NOUN'),\n",
       " Token(lemma='atmosphere', POS='NOUN'),\n",
       " Token(lemma='shop', POS='NOUN'),\n",
       " Token(lemma='management', POS='NOUN'),\n",
       " Token(lemma='pressure', POS='NOUN'),\n",
       " Token(lemma='tour', POS='NOUN'),\n",
       " Token(lemma='reject', POS='VERB'),\n",
       " Token(lemma='affect', POS='VERB'),\n",
       " Token(lemma='operate', POS='VERB'),\n",
       " Token(lemma='speaker', POS='NOUN'),\n",
       " Token(lemma='ability', POS='NOUN'),\n",
       " Token(lemma='percent', POS='NOUN'),\n",
       " Token(lemma='albanian', POS='ADJ'),\n",
       " Token(lemma='trade', POS='NOUN'),\n",
       " Token(lemma='turkish', POS='ADJ'),\n",
       " Token(lemma='farm', POS='NOUN'),\n",
       " Token(lemma='empire', POS='NOUN'),\n",
       " Token(lemma='camera', POS='NOUN'),\n",
       " Token(lemma='exception', POS='NOUN'),\n",
       " Token(lemma='analysis', POS='NOUN'),\n",
       " Token(lemma='constellation', POS='NOUN'),\n",
       " Token(lemma='wrong', POS='ADJ'),\n",
       " Token(lemma='distance', POS='NOUN'),\n",
       " Token(lemma='origin', POS='NOUN'),\n",
       " Token(lemma='mountain', POS='NOUN'),\n",
       " Token(lemma='pet', POS='NOUN'),\n",
       " Token(lemma='deliver', POS='VERB'),\n",
       " Token(lemma='resource', POS='NOUN'),\n",
       " Token(lemma='active', POS='ADJ'),\n",
       " Token(lemma='scientist', POS='NOUN'),\n",
       " Token(lemma='frog', POS='NOUN'),\n",
       " Token(lemma='literature', POS='NOUN'),\n",
       " Token(lemma='design', POS='VERB'),\n",
       " Token(lemma='novel', POS='NOUN'),\n",
       " Token(lemma='latin', POS='ADJ'),\n",
       " Token(lemma='salt', POS='NOUN'),\n",
       " Token(lemma='stock', POS='NOUN'),\n",
       " Token(lemma='ad', POS='NOUN'),\n",
       " Token(lemma='huge', POS='ADJ'),\n",
       " Token(lemma='citizen', POS='NOUN'),\n",
       " Token(lemma='serious', POS='ADJ'),\n",
       " Token(lemma='realize', POS='VERB'),\n",
       " Token(lemma='vehicle', POS='NOUN'),\n",
       " Token(lemma='promote', POS='VERB'),\n",
       " Token(lemma='rise', POS='VERB'),\n",
       " Token(lemma='face', POS='NOUN'),\n",
       " Token(lemma='improve', POS='VERB'),\n",
       " Token(lemma='initial', POS='ADJ'),\n",
       " Token(lemma='tend', POS='VERB'),\n",
       " Token(lemma='institution', POS='NOUN'),\n",
       " Token(lemma='tv', POS='NOUN'),\n",
       " Token(lemma='formal', POS='ADJ'),\n",
       " Token(lemma='command', POS='NOUN'),\n",
       " Token(lemma='television', POS='NOUN'),\n",
       " Token(lemma='request', POS='VERB'),\n",
       " Token(lemma='correspond', POS='VERB'),\n",
       " Token(lemma='jurisdiction', POS='NOUN'),\n",
       " Token(lemma='spacecraft', POS='NOUN'),\n",
       " Token(lemma='length', POS='NOUN'),\n",
       " Token(lemma='telescope', POS='NOUN'),\n",
       " Token(lemma='murder', POS='NOUN'),\n",
       " Token(lemma='future', POS='ADJ'),\n",
       " Token(lemma='execute', POS='VERB'),\n",
       " Token(lemma='crop', POS='NOUN'),\n",
       " Token(lemma='key', POS='ADJ'),\n",
       " Token(lemma='limited', POS='ADJ'),\n",
       " Token(lemma='fresh', POS='ADJ'),\n",
       " Token(lemma='basic', POS='ADJ'),\n",
       " Token(lemma='train', POS='VERB'),\n",
       " Token(lemma='manager', POS='NOUN'),\n",
       " Token(lemma='select', POS='VERB'),\n",
       " Token(lemma='philosopher', POS='NOUN'),\n",
       " Token(lemma='tribe', POS='NOUN'),\n",
       " Token(lemma='surround', POS='VERB'),\n",
       " Token(lemma='known', POS='ADJ'),\n",
       " Token(lemma='20th', POS='ADJ'),\n",
       " Token(lemma='cause', POS='NOUN'),\n",
       " Token(lemma='english', POS='ADJ'),\n",
       " Token(lemma='no.', POS='NOUN'),\n",
       " Token(lemma='skin', POS='NOUN'),\n",
       " Token(lemma='potassium', POS='NOUN'),\n",
       " Token(lemma='judge', POS='NOUN'),\n",
       " Token(lemma='fire', POS='NOUN'),\n",
       " Token(lemma='responsible', POS='ADJ'),\n",
       " Token(lemma='procedure', POS='NOUN'),\n",
       " Token(lemma='marry', POS='VERB'),\n",
       " Token(lemma='acquire', POS='VERB'),\n",
       " Token(lemma='software', POS='NOUN'),\n",
       " Token(lemma='x', POS='NOUN'),\n",
       " Token(lemma='reference', POS='NOUN'),\n",
       " Token(lemma='list', POS='VERB'),\n",
       " Token(lemma='claim', POS='NOUN'),\n",
       " Token(lemma='multiple', POS='ADJ'),\n",
       " Token(lemma='assist', POS='VERB'),\n",
       " Token(lemma='green', POS='ADJ'),\n",
       " Token(lemma='soil', POS='NOUN'),\n",
       " Token(lemma='critical', POS='ADJ'),\n",
       " Token(lemma='unique', POS='ADJ'),\n",
       " Token(lemma='historian', POS='NOUN'),\n",
       " Token(lemma='gain', POS='VERB'),\n",
       " Token(lemma='budget', POS='NOUN'),\n",
       " Token(lemma='performance', POS='NOUN'),\n",
       " Token(lemma='general', POS='NOUN'),\n",
       " Token(lemma='contribute', POS='VERB'),\n",
       " Token(lemma='oxygen', POS='NOUN'),\n",
       " Token(lemma='station', POS='NOUN'),\n",
       " Token(lemma='iraqi', POS='ADJ'),\n",
       " Token(lemma='issue', POS='VERB'),\n",
       " Token(lemma='commercial', POS='ADJ'),\n",
       " Token(lemma='beautiful', POS='ADJ'),\n",
       " Token(lemma='thousand', POS='NOUN'),\n",
       " Token(lemma='context', POS='NOUN'),\n",
       " Token(lemma='annual', POS='ADJ'),\n",
       " Token(lemma='quantity', POS='NOUN'),\n",
       " Token(lemma='shoot', POS='VERB'),\n",
       " Token(lemma='belong', POS='VERB'),\n",
       " Token(lemma='measure', POS='VERB'),\n",
       " Token(lemma='volume', POS='NOUN'),\n",
       " Token(lemma='carbon', POS='NOUN'),\n",
       " Token(lemma='snake', POS='NOUN'),\n",
       " Token(lemma='lithium', POS='NOUN'),\n",
       " Token(lemma='equal', POS='ADJ'),\n",
       " Token(lemma='experience', POS='VERB'),\n",
       " Token(lemma='web', POS='NOUN'),\n",
       " Token(lemma='ready', POS='ADJ'),\n",
       " Token(lemma='ok', POS='ADJ'),\n",
       " Token(lemma='fit', POS='VERB'),\n",
       " Token(lemma='manage', POS='VERB'),\n",
       " Token(lemma='description', POS='NOUN'),\n",
       " Token(lemma='fourth', POS='ADJ'),\n",
       " Token(lemma='file', POS='VERB'),\n",
       " Token(lemma='emerge', POS='VERB'),\n",
       " Token(lemma='teach', POS='VERB'),\n",
       " Token(lemma='club', POS='NOUN'),\n",
       " Token(lemma='cruise', POS='NOUN'),\n",
       " Token(lemma='sport', POS='NOUN'),\n",
       " Token(lemma='fall', POS='NOUN'),\n",
       " Token(lemma='earliest', POS='ADJ'),\n",
       " Token(lemma='bond', POS='NOUN'),\n",
       " Token(lemma='tail', POS='NOUN'),\n",
       " Token(lemma='port', POS='NOUN'),\n",
       " Token(lemma='vet', POS='NOUN'),\n",
       " Token(lemma='scientific', POS='ADJ'),\n",
       " Token(lemma='complex', POS='ADJ'),\n",
       " Token(lemma='baby', POS='NOUN'),\n",
       " Token(lemma='fuel', POS='NOUN'),\n",
       " Token(lemma='adopt', POS='VERB'),\n",
       " Token(lemma='instance', POS='NOUN'),\n",
       " Token(lemma='mathematics', POS='NOUN'),\n",
       " Token(lemma='alpha', POS='NOUN'),\n",
       " Token(lemma='bitumen', POS='NOUN'),\n",
       " Token(lemma='communion', POS='NOUN'),\n",
       " Token(lemma='actinium', POS='NOUN'),\n",
       " Token(lemma='wheel', POS='NOUN'),\n",
       " Token(lemma='show', POS='NOUN'),\n",
       " Token(lemma='past', POS='ADJ'),\n",
       " Token(lemma='none', POS='NOUN'),\n",
       " Token(lemma='address', POS='VERB'),\n",
       " Token(lemma='complete', POS='ADJ'),\n",
       " Token(lemma='differ', POS='VERB'),\n",
       " Token(lemma='discussion', POS='NOUN'),\n",
       " Token(lemma='awesome', POS='ADJ'),\n",
       " Token(lemma='suggestion', POS='NOUN'),\n",
       " Token(lemma='box', POS='NOUN'),\n",
       " Token(lemma='earlier', POS='ADJ'),\n",
       " Token(lemma='pattern', POS='NOUN'),\n",
       " Token(lemma='marriage', POS='NOUN'),\n",
       " Token(lemma='demonstrate', POS='VERB'),\n",
       " Token(lemma='respond', POS='VERB'),\n",
       " Token(lemma='older', POS='ADJ'),\n",
       " Token(lemma='writing', POS='NOUN'),\n",
       " Token(lemma='radiation', POS='NOUN'),\n",
       " Token(lemma='instruction', POS='NOUN'),\n",
       " Token(lemma='advance', POS='NOUN'),\n",
       " Token(lemma='motion', POS='NOUN'),\n",
       " Token(lemma='limit', POS='VERB'),\n",
       " Token(lemma='asphalt', POS='NOUN'),\n",
       " Token(lemma='ambiguity', POS='NOUN'),\n",
       " Token(lemma='anglican', POS='ADJ'),\n",
       " Token(lemma='appreciate', POS='VERB'),\n",
       " Token(lemma='ensure', POS='VERB'),\n",
       " Token(lemma='error', POS='NOUN'),\n",
       " Token(lemma='contact', POS='VERB'),\n",
       " Token(lemma='lack', POS='VERB'),\n",
       " Token(lemma='sector', POS='NOUN'),\n",
       " Token(lemma='sound', POS='VERB'),\n",
       " Token(lemma='generate', POS='VERB'),\n",
       " Token(lemma='category', POS='NOUN'),\n",
       " Token(lemma='gift', POS='NOUN'),\n",
       " Token(lemma='reasonable', POS='ADJ'),\n",
       " Token(lemma='worth', POS='ADJ'),\n",
       " Token(lemma='worst', POS='ADJ'),\n",
       " Token(lemma='ethnic', POS='ADJ'),\n",
       " Token(lemma='debate', POS='NOUN'),\n",
       " Token(lemma='afghan', POS='ADJ'),\n",
       " Token(lemma='network', POS='NOUN'),\n",
       " Token(lemma='collect', POS='VERB'),\n",
       " Token(lemma='equipment', POS='NOUN'),\n",
       " Token(lemma='drug', POS='NOUN'),\n",
       " Token(lemma='appoint', POS='VERB'),\n",
       " Token(lemma='hearing', POS='NOUN'),\n",
       " Token(lemma='modify', POS='VERB'),\n",
       " Token(lemma='mineral', POS='NOUN'),\n",
       " Token(lemma='anatomy', POS='NOUN'),\n",
       " Token(lemma='amphibian', POS='NOUN'),\n",
       " Token(lemma='arab', POS='ADJ'),\n",
       " Token(lemma='road', POS='NOUN'),\n",
       " Token(lemma='view', POS='VERB'),\n",
       " Token(lemma='future', POS='NOUN'),\n",
       " Token(lemma='meal', POS='NOUN'),\n",
       " Token(lemma='mark', POS='VERB'),\n",
       " Token(lemma='positive', POS='ADJ'),\n",
       " Token(lemma='payment', POS='NOUN'),\n",
       " Token(lemma='notice', POS='VERB'),\n",
       " Token(lemma='heavy', POS='ADJ'),\n",
       " Token(lemma='female', POS='NOUN'),\n",
       " Token(lemma='lunch', POS='NOUN'),\n",
       " Token(lemma='meat', POS='NOUN'),\n",
       " Token(lemma='perfect', POS='ADJ'),\n",
       " Token(lemma='fast', POS='ADJ'),\n",
       " Token(lemma='push', POS='VERB'),\n",
       " Token(lemma='requirement', POS='NOUN'),\n",
       " Token(lemma='brother', POS='NOUN'),\n",
       " Token(lemma='increase', POS='NOUN'),\n",
       " Token(lemma='contrast', POS='NOUN'),\n",
       " Token(lemma='employ', POS='VERB'),\n",
       " Token(lemma='difficulty', POS='NOUN'),\n",
       " Token(lemma='aspect', POS='NOUN'),\n",
       " Token(lemma='distinct', POS='ADJ'),\n",
       " Token(lemma='appearance', POS='NOUN'),\n",
       " Token(lemma='muscle', POS='NOUN'),\n",
       " Token(lemma='sequence', POS='NOUN'),\n",
       " Token(lemma='formation', POS='NOUN'),\n",
       " Token(lemma='edition', POS='NOUN'),\n",
       " Token(lemma='amateur', POS='ADJ'),\n",
       " Token(lemma='wide', POS='ADJ'),\n",
       " Token(lemma='depict', POS='VERB'),\n",
       " Token(lemma='wolf', POS='NOUN'),\n",
       " Token(lemma='street', POS='NOUN'),\n",
       " Token(lemma='heart', POS='NOUN'),\n",
       " Token(lemma='income', POS='NOUN'),\n",
       " Token(lemma='classical', POS='ADJ'),\n",
       " Token(lemma='forward', POS='VERB'),\n",
       " Token(lemma='hot', POS='ADJ'),\n",
       " Token(lemma='listen', POS='VERB'),\n",
       " Token(lemma='wear', POS='VERB'),\n",
       " Token(lemma='firm', POS='NOUN'),\n",
       " Token(lemma='delivery', POS='NOUN'),\n",
       " Token(lemma='miss', POS='VERB'),\n",
       " Token(lemma='play', POS='NOUN'),\n",
       " Token(lemma='visit', POS='NOUN'),\n",
       " Token(lemma='construction', POS='NOUN'),\n",
       " Token(lemma='era', POS='NOUN'),\n",
       " Token(lemma='spread', POS='VERB'),\n",
       " Token(lemma='studio', POS='NOUN'),\n",
       " Token(lemma='heat', POS='NOUN'),\n",
       " Token(lemma='individual', POS='ADJ'),\n",
       " Token(lemma='suicide', POS='NOUN'),\n",
       " Token(lemma='pronunciation', POS='NOUN'),\n",
       " Token(lemma='wonder', POS='VERB'),\n",
       " Token(lemma='print', POS='VERB'),\n",
       " Token(lemma='demand', POS='NOUN'),\n",
       " Token(lemma='scene', POS='NOUN'),\n",
       " Token(lemma='guess', POS='VERB'),\n",
       " Token(lemma='experiment', POS='NOUN'),\n",
       " Token(lemma='finish', POS='VERB'),\n",
       " Token(lemma='wish', POS='VERB'),\n",
       " Token(lemma='unable', POS='ADJ'),\n",
       " Token(lemma='speed', POS='NOUN'),\n",
       " Token(lemma='rock', POS='NOUN'),\n",
       " Token(lemma='district', POS='NOUN'),\n",
       " Token(lemma='conduct', POS='VERB'),\n",
       " Token(lemma='cheap', POS='ADJ'),\n",
       " Token(lemma='rule', POS='VERB'),\n",
       " Token(lemma='teacher', POS='NOUN'),\n",
       " Token(lemma='interview', POS='NOUN'),\n",
       " Token(lemma='care', POS='VERB'),\n",
       " Token(lemma='pizza', POS='NOUN'),\n",
       " Token(lemma='ice', POS='NOUN'),\n",
       " Token(lemma='regular', POS='ADJ'),\n",
       " Token(lemma='press', POS='NOUN'),\n",
       " Token(lemma='machine', POS='NOUN'),\n",
       " Token(lemma='measure', POS='NOUN'),\n",
       " Token(lemma='subsequent', POS='ADJ'),\n",
       " Token(lemma='committee', POS='NOUN'),\n",
       " Token(lemma='anthrax', POS='NOUN'),\n",
       " Token(lemma='deposit', POS='NOUN'),\n",
       " Token(lemma='layer', POS='NOUN'),\n",
       " Token(lemma='wave', POS='NOUN'),\n",
       " Token(lemma='freedom', POS='NOUN'),\n",
       " Token(lemma='vote', POS='NOUN'),\n",
       " Token(lemma='voice', POS='NOUN'),\n",
       " Token(lemma='lie', POS='VERB'),\n",
       " Token(lemma='pull', POS='VERB'),\n",
       " Token(lemma='historical', POS='ADJ'),\n",
       " Token(lemma='schedule', POS='VERB'),\n",
       " Token(lemma='engage', POS='VERB'),\n",
       " Token(lemma='skill', POS='NOUN'),\n",
       " Token(lemma='escape', POS='VERB'),\n",
       " Token(lemma='answer', POS='VERB'),\n",
       " Token(lemma='mechanic', POS='NOUN'),\n",
       " Token(lemma='bar', POS='NOUN'),\n",
       " Token(lemma='defend', POS='VERB'),\n",
       " Token(lemma='pure', POS='ADJ'),\n",
       " Token(lemma='host', POS='VERB'),\n",
       " Token(lemma='duty', POS='NOUN'),\n",
       " Token(lemma='rich', POS='ADJ'),\n",
       " Token(lemma='red', POS='ADJ'),\n",
       " Token(lemma='1960', POS='NOUN'),\n",
       " Token(lemma='pregnancy', POS='NOUN'),\n",
       " Token(lemma='failure', POS='NOUN'),\n",
       " Token(lemma='temple', POS='NOUN'),\n",
       " Token(lemma='conclude', POS='VERB'),\n",
       " Token(lemma='range', POS='VERB'),\n",
       " Token(lemma='defendant', POS='NOUN'),\n",
       " Token(lemma='producer', POS='NOUN'),\n",
       " Token(lemma='bind', POS='VERB'),\n",
       " Token(lemma='rise', POS='NOUN'),\n",
       " Token(lemma='anxiety', POS='NOUN'),\n",
       " Token(lemma=')', POS='NOUN'),\n",
       " Token(lemma='galaxy', POS='NOUN'),\n",
       " Token(lemma='salamander', POS='NOUN'),\n",
       " Token(lemma='algae', POS='NOUN'),\n",
       " Token(lemma='move', POS='NOUN'),\n",
       " Token(lemma='wall', POS='NOUN'),\n",
       " Token(lemma='boy', POS='NOUN'),\n",
       " Token(lemma='blow', POS='VERB'),\n",
       " Token(lemma='admit', POS='VERB'),\n",
       " Token(lemma='concern', POS='VERB'),\n",
       " Token(lemma='distribution', POS='NOUN'),\n",
       " Token(lemma='live', POS='ADJ'),\n",
       " Token(lemma='moment', POS='NOUN'),\n",
       " Token(lemma='tourist', POS='NOUN'),\n",
       " Token(lemma='throw', POS='VERB'),\n",
       " Token(lemma='withdraw', POS='VERB'),\n",
       " Token(lemma='incorporate', POS='VERB'),\n",
       " Token(lemma='irish', POS='ADJ'),\n",
       " Token(lemma='beat', POS='VERB'),\n",
       " Token(lemma='daily', POS='ADJ'),\n",
       " Token(lemma='transaction', POS='NOUN'),\n",
       " Token(lemma='spring', POS='NOUN'),\n",
       " Token(lemma='benefit', POS='NOUN'),\n",
       " Token(lemma='absolute', POS='ADJ'),\n",
       " Token(lemma='football', POS='NOUN'),\n",
       " Token(lemma='earth', POS='NOUN'),\n",
       " Token(lemma='audience', POS='NOUN'),\n",
       " Token(lemma='existence', POS='NOUN'),\n",
       " Token(lemma='astronomy', POS='NOUN'),\n",
       " Token(lemma='factory', POS='NOUN'),\n",
       " Token(lemma='roman', POS='ADJ'),\n",
       " Token(lemma='strategy', POS='NOUN'),\n",
       " Token(lemma='cite', POS='VERB'),\n",
       " Token(lemma='expression', POS='NOUN'),\n",
       " Token(lemma='reveal', POS='VERB'),\n",
       " Token(lemma='counterparty', POS='NOUN'),\n",
       " Token(lemma='stuff', POS='NOUN'),\n",
       " Token(lemma='card', POS='NOUN'),\n",
       " Token(lemma='sample', POS='NOUN'),\n",
       " Token(lemma='correct', POS='ADJ'),\n",
       " Token(lemma='candidate', POS='NOUN'),\n",
       " Token(lemma='album', POS='NOUN'),\n",
       " Token(lemma='willing', POS='ADJ'),\n",
       " Token(lemma='waste', POS='NOUN'),\n",
       " Token(lemma='rude', POS='ADJ'),\n",
       " Token(lemma='truth', POS='NOUN'),\n",
       " Token(lemma='pain', POS='NOUN'),\n",
       " Token(lemma='launch', POS='NOUN'),\n",
       " Token(lemma='notion', POS='NOUN'),\n",
       " Token(lemma='lawyer', POS='NOUN'),\n",
       " Token(lemma='total', POS='NOUN'),\n",
       " Token(lemma='like', POS='ADJ'),\n",
       " Token(lemma='tool', POS='NOUN'),\n",
       " Token(lemma='fear', POS='NOUN'),\n",
       " Token(lemma='minority', POS='NOUN'),\n",
       " Token(lemma='translate', POS='VERB'),\n",
       " Token(lemma='native', POS='ADJ'),\n",
       " Token(lemma='persian', POS='ADJ'),\n",
       " Token(lemma='algerian', POS='ADJ'),\n",
       " Token(lemma='safe', POS='ADJ'),\n",
       " Token(lemma='occupy', POS='VERB'),\n",
       " Token(lemma='fun', POS='NOUN'),\n",
       " Token(lemma='communication', POS='NOUN'),\n",
       " Token(lemma='forget', POS='VERB'),\n",
       " Token(lemma='extreme', POS='ADJ'),\n",
       " Token(lemma='revise', POS='VERB'),\n",
       " Token(lemma='implement', POS='VERB'),\n",
       " Token(lemma='client', POS='NOUN'),\n",
       " Token(lemma='tomorrow', POS='NOUN'),\n",
       " Token(lemma='master', POS='NOUN'),\n",
       " Token(lemma='advice', POS='NOUN'),\n",
       " Token(lemma='share', POS='NOUN'),\n",
       " Token(lemma='intelligence', POS='NOUN'),\n",
       " Token(lemma='crime', POS='NOUN'),\n",
       " Token(lemma='dangerous', POS='ADJ'),\n",
       " Token(lemma='potential', POS='ADJ'),\n",
       " Token(lemma='chain', POS='NOUN'),\n",
       " Token(lemma='greatest', POS='ADJ'),\n",
       " Token(lemma='portion', POS='NOUN'),\n",
       " Token(lemma='islamic', POS='ADJ'),\n",
       " Token(lemma='spelling', POS='NOUN'),\n",
       " Token(lemma='politics', POS='NOUN'),\n",
       " Token(lemma='memory', POS='NOUN'),\n",
       " Token(lemma='abandon', POS='VERB'),\n",
       " Token(lemma='current', POS='NOUN'),\n",
       " Token(lemma='behavior', POS='NOUN'),\n",
       " Token(lemma='stone', POS='NOUN'),\n",
       " Token(lemma='concentration', POS='NOUN'),\n",
       " Token(lemma='start', POS='NOUN'),\n",
       " Token(lemma='sister', POS='NOUN'),\n",
       " Token(lemma='retain', POS='VERB'),\n",
       " Token(lemma='emission', POS='NOUN'),\n",
       " Token(lemma='actor', POS='NOUN'),\n",
       " Token(lemma='americium', POS='NOUN'),\n",
       " Token(lemma='suppose', POS='VERB'),\n",
       " Token(lemma='promise', POS='VERB'),\n",
       " Token(lemma='explore', POS='VERB'),\n",
       " Token(lemma='release', POS='NOUN'),\n",
       " Token(lemma='double', POS='ADJ'),\n",
       " Token(lemma='trust', POS='VERB'),\n",
       " Token(lemma='department', POS='NOUN'),\n",
       " Token(lemma='post', POS='NOUN'),\n",
       " Token(lemma='medicine', POS='NOUN'),\n",
       " Token(lemma='warm', POS='ADJ'),\n",
       " Token(lemma='chicken', POS='NOUN'),\n",
       " Token(lemma='impossible', POS='ADJ'),\n",
       " Token(lemma='wing', POS='NOUN'),\n",
       " Token(lemma='ton', POS='NOUN'),\n",
       " Token(lemma='solar', POS='ADJ'),\n",
       " Token(lemma='drive', POS='NOUN'),\n",
       " Token(lemma='advise', POS='VERB'),\n",
       " Token(lemma='possibility', POS='NOUN'),\n",
       " Token(lemma='reserve', POS='NOUN'),\n",
       " Token(lemma='powerful', POS='ADJ'),\n",
       " Token(lemma='rabbit', POS='NOUN'),\n",
       " Token(lemma='estimate', POS='NOUN'),\n",
       " Token(lemma='digital', POS='ADJ'),\n",
       " Token(lemma='deep', POS='ADJ'),\n",
       " Token(lemma='stability', POS='NOUN'),\n",
       " Token(lemma='dominate', POS='VERB'),\n",
       " Token(lemma='comprise', POS='VERB'),\n",
       " Token(lemma='injury', POS='NOUN'),\n",
       " Token(lemma='consistent', POS='ADJ'),\n",
       " Token(lemma='discovery', POS='NOUN'),\n",
       " Token(lemma='notable', POS='ADJ'),\n",
       " Token(lemma='spectral', POS='ADJ'),\n",
       " Token(lemma='anthropology', POS='NOUN'),\n",
       " Token(lemma='search', POS='NOUN'),\n",
       " Token(lemma='award', POS='VERB'),\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all the target vocabulary\n",
    "target_vocabulary._index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-wayne",
   "metadata": {},
   "source": [
    "#### -- Context Words --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-spiritual",
   "metadata": {},
   "source": [
    "#### Option 1: Only keep lemma "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "imposed-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vocabulary = corpus.create_vocabulary(attributes=(\"lemma\"), \n",
    "                                              filters = [ stopwords_filter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-latest",
   "metadata": {},
   "source": [
    "#### Option 2: Keep lemma and POS with \"VERB\" or \"ADJ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tutorial-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_filter_context = mangoes.corpus.filter_by_attribute(\"POS\",[\"NOUN\", \"VERB\", \"ADJ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "powerful-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vocabulary = corpus.create_vocabulary(attributes=(\"lemma\",\"POS\"), \n",
    "                                            filters = [ stopwords_filter_lemma,\n",
    "                                                        pos_filter_context])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-recycling",
   "metadata": {},
   "source": [
    "#### Check context vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "muslim-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21237 words will be used as target vocabulary\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(context_vocabulary)} words will be used as target vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "micro-trout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token(lemma='use', POS='VERB'),\n",
       " Token(lemma='time', POS='NOUN'),\n",
       " Token(lemma='make', POS='VERB'),\n",
       " Token(lemma='year', POS='NOUN'),\n",
       " Token(lemma='go', POS='VERB'),\n",
       " Token(lemma='know', POS='VERB'),\n",
       " Token(lemma='get', POS='VERB'),\n",
       " Token(lemma='take', POS='VERB'),\n",
       " Token(lemma='include', POS='VERB'),\n",
       " Token(lemma='say', POS='VERB'),\n",
       " Token(lemma='many', POS='ADJ'),\n",
       " Token(lemma='first', POS='ADJ'),\n",
       " Token(lemma='give', POS='VERB'),\n",
       " Token(lemma='number', POS='NOUN'),\n",
       " Token(lemma='see', POS='VERB'),\n",
       " Token(lemma='call', POS='VERB'),\n",
       " Token(lemma='day', POS='NOUN'),\n",
       " Token(lemma='find', POS='VERB'),\n",
       " Token(lemma='state', POS='NOUN'),\n",
       " Token(lemma='people', POS='NOUN'),\n",
       " Token(lemma='new', POS='ADJ'),\n",
       " Token(lemma='become', POS='VERB'),\n",
       " Token(lemma='good', POS='ADJ'),\n",
       " Token(lemma='come', POS='VERB'),\n",
       " Token(lemma='want', POS='VERB'),\n",
       " Token(lemma='place', POS='NOUN'),\n",
       " Token(lemma='great', POS='ADJ'),\n",
       " Token(lemma='service', POS='NOUN'),\n",
       " Token(lemma='work', POS='NOUN'),\n",
       " Token(lemma='work', POS='VERB'),\n",
       " Token(lemma='think', POS='VERB'),\n",
       " Token(lemma='way', POS='NOUN'),\n",
       " Token(lemma='language', POS='NOUN'),\n",
       " Token(lemma='need', POS='VERB'),\n",
       " Token(lemma='country', POS='NOUN'),\n",
       " Token(lemma='part', POS='NOUN'),\n",
       " Token(lemma='system', POS='NOUN'),\n",
       " Token(lemma='group', POS='NOUN'),\n",
       " Token(lemma='write', POS='VERB'),\n",
       " Token(lemma='film', POS='NOUN'),\n",
       " Token(lemma='best', POS='ADJ'),\n",
       " Token(lemma='name', POS='NOUN'),\n",
       " Token(lemma='follow', POS='VERB'),\n",
       " Token(lemma='century', POS='NOUN'),\n",
       " Token(lemma='look', POS='VERB'),\n",
       " Token(lemma='life', POS='NOUN'),\n",
       " Token(lemma='food', POS='NOUN'),\n",
       " Token(lemma='world', POS='NOUN'),\n",
       " Token(lemma='family', POS='NOUN'),\n",
       " Token(lemma='area', POS='NOUN'),\n",
       " Token(lemma='water', POS='NOUN'),\n",
       " Token(lemma='try', POS='VERB'),\n",
       " Token(lemma='war', POS='NOUN'),\n",
       " Token(lemma='example', POS='NOUN'),\n",
       " Token(lemma='several', POS='ADJ'),\n",
       " Token(lemma='leave', POS='VERB'),\n",
       " Token(lemma='thanks', POS='NOUN'),\n",
       " Token(lemma='form', POS='NOUN'),\n",
       " Token(lemma='word', POS='NOUN'),\n",
       " Token(lemma='order', POS='NOUN'),\n",
       " Token(lemma='form', POS='VERB'),\n",
       " Token(lemma='company', POS='NOUN'),\n",
       " Token(lemma='government', POS='NOUN'),\n",
       " Token(lemma='city', POS='NOUN'),\n",
       " Token(lemma='help', POS='VERB'),\n",
       " Token(lemma='tell', POS='VERB'),\n",
       " Token(lemma='case', POS='NOUN'),\n",
       " Token(lemma='last', POS='ADJ'),\n",
       " Token(lemma='consider', POS='VERB'),\n",
       " Token(lemma='begin', POS='VERB'),\n",
       " Token(lemma='different', POS='ADJ'),\n",
       " Token(lemma='thing', POS='NOUN'),\n",
       " Token(lemma='provide', POS='VERB'),\n",
       " Token(lemma='live', POS='VERB'),\n",
       " Token(lemma='send', POS='VERB'),\n",
       " Token(lemma='metal', POS='NOUN'),\n",
       " Token(lemma='small', POS='ADJ'),\n",
       " Token(lemma='high', POS='ADJ'),\n",
       " Token(lemma='early', POS='ADJ'),\n",
       " Token(lemma='base', POS='VERB'),\n",
       " Token(lemma='term', POS='NOUN'),\n",
       " Token(lemma='one', POS='NOUN'),\n",
       " Token(lemma='large', POS='ADJ'),\n",
       " Token(lemma='let', POS='VERB'),\n",
       " Token(lemma='force', POS='NOUN'),\n",
       " Token(lemma='show', POS='VERB'),\n",
       " Token(lemma='price', POS='NOUN'),\n",
       " Token(lemma='element', POS='NOUN'),\n",
       " Token(lemma='point', POS='NOUN'),\n",
       " Token(lemma='lead', POS='VERB'),\n",
       " Token(lemma='develop', POS='VERB'),\n",
       " Token(lemma='court', POS='NOUN'),\n",
       " Token(lemma='remain', POS='VERB'),\n",
       " Token(lemma='end', POS='NOUN'),\n",
       " Token(lemma='like', POS='VERB'),\n",
       " Token(lemma='receive', POS='VERB'),\n",
       " Token(lemma='member', POS='NOUN'),\n",
       " Token(lemma='week', POS='NOUN'),\n",
       " Token(lemma='start', POS='VERB'),\n",
       " Token(lemma='letter', POS='NOUN'),\n",
       " Token(lemma='move', POS='VERB'),\n",
       " Token(lemma='problem', POS='NOUN'),\n",
       " Token(lemma='mean', POS='VERB'),\n",
       " Token(lemma='ask', POS='VERB'),\n",
       " Token(lemma='keep', POS='VERB'),\n",
       " Token(lemma='american', POS='ADJ'),\n",
       " Token(lemma='man', POS='NOUN'),\n",
       " Token(lemma='put', POS='VERB'),\n",
       " Token(lemma='hold', POS='VERB'),\n",
       " Token(lemma='death', POS='NOUN'),\n",
       " Token(lemma='feel', POS='VERB'),\n",
       " Token(lemma='produce', POS='VERB'),\n",
       " Token(lemma='power', POS='NOUN'),\n",
       " Token(lemma='type', POS='NOUN'),\n",
       " Token(lemma='month', POS='NOUN'),\n",
       " Token(lemma='change', POS='NOUN'),\n",
       " Token(lemma='book', POS='NOUN'),\n",
       " Token(lemma='continue', POS='VERB'),\n",
       " Token(lemma='animal', POS='NOUN'),\n",
       " Token(lemma='accord', POS='VERB'),\n",
       " Token(lemma='energy', POS='NOUN'),\n",
       " Token(lemma='use', POS='NOUN'),\n",
       " Token(lemma='art', POS='NOUN'),\n",
       " Token(lemma='win', POS='VERB'),\n",
       " Token(lemma='play', POS='VERB'),\n",
       " Token(lemma='create', POS='VERB'),\n",
       " Token(lemma='little', POS='ADJ'),\n",
       " Token(lemma='star', POS='NOUN'),\n",
       " Token(lemma='population', POS='NOUN'),\n",
       " Token(lemma='next', POS='ADJ'),\n",
       " Token(lemma='question', POS='NOUN'),\n",
       " Token(lemma='set', POS='NOUN'),\n",
       " Token(lemma='allow', POS='VERB'),\n",
       " Token(lemma='pm', POS='NOUN'),\n",
       " Token(lemma='common', POS='ADJ'),\n",
       " Token(lemma='modern', POS='ADJ'),\n",
       " Token(lemma='line', POS='NOUN'),\n",
       " Token(lemma='region', POS='NOUN'),\n",
       " Token(lemma='school', POS='NOUN'),\n",
       " Token(lemma='believe', POS='VERB'),\n",
       " Token(lemma='add', POS='VERB'),\n",
       " Token(lemma='issue', POS='NOUN'),\n",
       " Token(lemma='period', POS='NOUN'),\n",
       " Token(lemma='second', POS='ADJ'),\n",
       " Token(lemma='body', POS='NOUN'),\n",
       " Token(lemma='process', POS='NOUN'),\n",
       " Token(lemma='hour', POS='NOUN'),\n",
       " Token(lemma='law', POS='NOUN'),\n",
       " Token(lemma='major', POS='ADJ'),\n",
       " Token(lemma='pay', POS='VERB'),\n",
       " Token(lemma='result', POS='NOUN'),\n",
       " Token(lemma='atom', POS='NOUN'),\n",
       " Token(lemma='lose', POS='VERB'),\n",
       " Token(lemma='lot', POS='NOUN'),\n",
       " Token(lemma='refer', POS='VERB'),\n",
       " Token(lemma='level', POS='NOUN'),\n",
       " Token(lemma='product', POS='NOUN'),\n",
       " Token(lemma='car', POS='NOUN'),\n",
       " Token(lemma='set', POS='VERB'),\n",
       " Token(lemma='recommend', POS='VERB'),\n",
       " Token(lemma='friend', POS='NOUN'),\n",
       " Token(lemma='occur', POS='VERB'),\n",
       " Token(lemma='space', POS='NOUN'),\n",
       " Token(lemma='represent', POS='VERB'),\n",
       " Token(lemma='long', POS='ADJ'),\n",
       " Token(lemma='old', POS='ADJ'),\n",
       " Token(lemma='job', POS='NOUN'),\n",
       " Token(lemma='meet', POS='VERB'),\n",
       " Token(lemma='hand', POS='NOUN'),\n",
       " Token(lemma='oil', POS='NOUN'),\n",
       " Token(lemma='rate', POS='NOUN'),\n",
       " Token(lemma='today', POS='NOUN'),\n",
       " Token(lemma='child', POS='NOUN'),\n",
       " Token(lemma='money', POS='NOUN'),\n",
       " Token(lemma='person', POS='NOUN'),\n",
       " Token(lemma='cause', POS='VERB'),\n",
       " Token(lemma='love', POS='VERB'),\n",
       " Token(lemma='able', POS='ADJ'),\n",
       " Token(lemma='production', POS='NOUN'),\n",
       " Token(lemma='seem', POS='VERB'),\n",
       " Token(lemma='speak', POS='VERB'),\n",
       " Token(lemma='largest', POS='ADJ'),\n",
       " Token(lemma='idea', POS='NOUN'),\n",
       " Token(lemma='land', POS='NOUN'),\n",
       " Token(lemma='require', POS='VERB'),\n",
       " Token(lemma='business', POS='NOUN'),\n",
       " Token(lemma='bring', POS='VERB'),\n",
       " Token(lemma='program', POS='NOUN'),\n",
       " Token(lemma='change', POS='VERB'),\n",
       " Token(lemma='describe', POS='VERB'),\n",
       " Token(lemma='read', POS='VERB'),\n",
       " Token(lemma='experience', POS='NOUN'),\n",
       " Token(lemma='acid', POS='NOUN'),\n",
       " Token(lemma='possible', POS='ADJ'),\n",
       " Token(lemma='team', POS='NOUN'),\n",
       " Token(lemma='publish', POS='VERB'),\n",
       " Token(lemma='contain', POS='VERB'),\n",
       " Token(lemma='development', POS='NOUN'),\n",
       " Token(lemma='office', POS='NOUN'),\n",
       " Token(lemma='final', POS='ADJ'),\n",
       " Token(lemma='reach', POS='VERB'),\n",
       " Token(lemma='much', POS='ADJ'),\n",
       " Token(lemma='species', POS='NOUN'),\n",
       " Token(lemma='history', POS='NOUN'),\n",
       " Token(lemma='position', POS='NOUN'),\n",
       " Token(lemma='free', POS='ADJ'),\n",
       " Token(lemma='amount', POS='NOUN'),\n",
       " Token(lemma='run', POS='VERB'),\n",
       " Token(lemma='sure', POS='ADJ'),\n",
       " Token(lemma='appear', POS='VERB'),\n",
       " Token(lemma='political', POS='ADJ'),\n",
       " Token(lemma='information', POS='NOUN'),\n",
       " Token(lemma='important', POS='ADJ'),\n",
       " Token(lemma='suggest', POS='VERB'),\n",
       " Token(lemma='name', POS='VERB'),\n",
       " Token(lemma='staff', POS='NOUN'),\n",
       " Token(lemma='increase', POS='VERB'),\n",
       " Token(lemma='choice', POS='NOUN'),\n",
       " Token(lemma='attach', POS='VERB'),\n",
       " Token(lemma='theory', POS='NOUN'),\n",
       " Token(lemma='human', POS='ADJ'),\n",
       " Token(lemma='natural', POS='ADJ'),\n",
       " Token(lemma='due', POS='ADJ'),\n",
       " Token(lemma='electron', POS='NOUN'),\n",
       " Token(lemma='better', POS='ADJ'),\n",
       " Token(lemma='establish', POS='VERB'),\n",
       " Token(lemma='model', POS='NOUN'),\n",
       " Token(lemma='return', POS='VERB'),\n",
       " Token(lemma='room', POS='NOUN'),\n",
       " Token(lemma='late', POS='ADJ'),\n",
       " Token(lemma='military', POS='ADJ'),\n",
       " Token(lemma='serve', POS='VERB'),\n",
       " Token(lemma='source', POS='NOUN'),\n",
       " Token(lemma='reason', POS='NOUN'),\n",
       " Token(lemma='die', POS='VERB'),\n",
       " Token(lemma='grow', POS='VERB'),\n",
       " Token(lemma='release', POS='VERB'),\n",
       " Token(lemma='character', POS='NOUN'),\n",
       " Token(lemma='fact', POS='NOUN'),\n",
       " Token(lemma='various', POS='ADJ'),\n",
       " Token(lemma='effect', POS='NOUN'),\n",
       " Token(lemma='abortion', POS='NOUN'),\n",
       " Token(lemma='army', POS='NOUN'),\n",
       " Token(lemma='list', POS='NOUN'),\n",
       " Token(lemma='control', POS='NOUN'),\n",
       " Token(lemma='action', POS='NOUN'),\n",
       " Token(lemma='gas', POS='NOUN'),\n",
       " Token(lemma='property', POS='NOUN'),\n",
       " Token(lemma='plant', POS='NOUN'),\n",
       " Token(lemma='game', POS='NOUN'),\n",
       " Token(lemma='phone', POS='NOUN'),\n",
       " Token(lemma='eat', POS='VERB'),\n",
       " Token(lemma='review', POS='NOUN'),\n",
       " Token(lemma='call', POS='NOUN'),\n",
       " Token(lemma='greek', POS='ADJ'),\n",
       " Token(lemma='support', POS='VERB'),\n",
       " Token(lemma='local', POS='ADJ'),\n",
       " Token(lemma='hear', POS='VERB'),\n",
       " Token(lemma='report', POS='VERB'),\n",
       " Token(lemma='turn', POS='VERB'),\n",
       " Token(lemma='night', POS='NOUN'),\n",
       " Token(lemma='ancient', POS='ADJ'),\n",
       " Token(lemma='international', POS='ADJ'),\n",
       " Token(lemma='result', POS='VERB'),\n",
       " Token(lemma='leader', POS='NOUN'),\n",
       " Token(lemma='home', POS='NOUN'),\n",
       " Token(lemma='offer', POS='VERB'),\n",
       " Token(lemma='study', POS='NOUN'),\n",
       " Token(lemma='age', POS='NOUN'),\n",
       " Token(lemma='similar', POS='ADJ'),\n",
       " Token(lemma='head', POS='NOUN'),\n",
       " Token(lemma='bc', POS='NOUN'),\n",
       " Token(lemma='light', POS='NOUN'),\n",
       " Token(lemma='structure', POS='NOUN'),\n",
       " Token(lemma='value', POS='NOUN'),\n",
       " Token(lemma='bear', POS='VERB'),\n",
       " Token(lemma='main', POS='ADJ'),\n",
       " Token(lemma='guy', POS='NOUN'),\n",
       " Token(lemma='buy', POS='VERB'),\n",
       " Token(lemma='british', POS='ADJ'),\n",
       " Token(lemma='culture', POS='NOUN'),\n",
       " Token(lemma='short', POS='ADJ'),\n",
       " Token(lemma='date', POS='NOUN'),\n",
       " Token(lemma='alphabet', POS='NOUN'),\n",
       " Token(lemma='customer', POS='NOUN'),\n",
       " Token(lemma='national', POS='ADJ'),\n",
       " Token(lemma='woman', POS='NOUN'),\n",
       " Token(lemma='report', POS='NOUN'),\n",
       " Token(lemma='vowel', POS='NOUN'),\n",
       " Token(lemma='project', POS='NOUN'),\n",
       " Token(lemma='minute', POS='NOUN'),\n",
       " Token(lemma='computer', POS='NOUN'),\n",
       " Token(lemma='agreement', POS='NOUN'),\n",
       " Token(lemma='field', POS='NOUN'),\n",
       " Token(lemma='axiom', POS='NOUN'),\n",
       " Token(lemma='public', POS='ADJ'),\n",
       " Token(lemma='election', POS='NOUN'),\n",
       " Token(lemma='available', POS='ADJ'),\n",
       " Token(lemma='son', POS='NOUN'),\n",
       " Token(lemma='build', POS='VERB'),\n",
       " Token(lemma='event', POS='NOUN'),\n",
       " Token(lemma='author', POS='NOUN'),\n",
       " Token(lemma='island', POS='NOUN'),\n",
       " Token(lemma='series', POS='NOUN'),\n",
       " Token(lemma='exist', POS='VERB'),\n",
       " Token(lemma='hope', POS='VERB'),\n",
       " Token(lemma='former', POS='ADJ'),\n",
       " Token(lemma='title', POS='NOUN'),\n",
       " Token(lemma='stay', POS='VERB'),\n",
       " Token(lemma='certain', POS='ADJ'),\n",
       " Token(lemma='full', POS='ADJ'),\n",
       " Token(lemma='script', POS='NOUN'),\n",
       " Token(lemma='pass', POS='VERB'),\n",
       " Token(lemma='kill', POS='VERB'),\n",
       " Token(lemma='state', POS='VERB'),\n",
       " Token(lemma='party', POS='NOUN'),\n",
       " Token(lemma='battle', POS='NOUN'),\n",
       " Token(lemma='talk', POS='VERB'),\n",
       " Token(lemma='music', POS='NOUN'),\n",
       " Token(lemma='locate', POS='VERB'),\n",
       " Token(lemma='email', POS='NOUN'),\n",
       " Token(lemma='meeting', POS='NOUN'),\n",
       " Token(lemma='site', POS='NOUN'),\n",
       " Token(lemma='lower', POS='ADJ'),\n",
       " Token(lemma='legal', POS='ADJ'),\n",
       " Token(lemma='deal', POS='NOUN'),\n",
       " Token(lemma='end', POS='VERB'),\n",
       " Token(lemma='campaign', POS='NOUN'),\n",
       " Token(lemma='class', POS='NOUN'),\n",
       " Token(lemma='device', POS='NOUN'),\n",
       " Token(lemma='strong', POS='ADJ'),\n",
       " Token(lemma='thank', POS='VERB'),\n",
       " Token(lemma='particular', POS='ADJ'),\n",
       " Token(lemma='interest', POS='NOUN'),\n",
       " Token(lemma='cat', POS='NOUN'),\n",
       " Token(lemma='nice', POS='ADJ'),\n",
       " Token(lemma='air', POS='NOUN'),\n",
       " Token(lemma='location', POS='NOUN'),\n",
       " Token(lemma='accept', POS='VERB'),\n",
       " Token(lemma='general', POS='ADJ'),\n",
       " Token(lemma='real', POS='ADJ'),\n",
       " Token(lemma='church', POS='NOUN'),\n",
       " Token(lemma='technology', POS='NOUN'),\n",
       " Token(lemma='version', POS='NOUN'),\n",
       " Token(lemma='regard', POS='VERB'),\n",
       " Token(lemma='single', POS='ADJ'),\n",
       " Token(lemma='define', POS='VERB'),\n",
       " Token(lemma='sell', POS='VERB'),\n",
       " Token(lemma='visit', POS='VERB'),\n",
       " Token(lemma='quality', POS='NOUN'),\n",
       " Token(lemma='side', POS='NOUN'),\n",
       " Token(lemma='story', POS='NOUN'),\n",
       " Token(lemma='attack', POS='NOUN'),\n",
       " Token(lemma='social', POS='ADJ'),\n",
       " Token(lemma='bad', POS='ADJ'),\n",
       " Token(lemma='market', POS='NOUN'),\n",
       " Token(lemma='house', POS='NOUN'),\n",
       " Token(lemma='territory', POS='NOUN'),\n",
       " Token(lemma='original', POS='ADJ'),\n",
       " Token(lemma='claim', POS='VERB'),\n",
       " Token(lemma='style', POS='NOUN'),\n",
       " Token(lemma='horse', POS='NOUN'),\n",
       " Token(lemma='text', POS='NOUN'),\n",
       " Token(lemma='western', POS='ADJ'),\n",
       " Token(lemma='decision', POS='NOUN'),\n",
       " Token(lemma='true', POS='ADJ'),\n",
       " Token(lemma='friendly', POS='ADJ'),\n",
       " Token(lemma='file', POS='NOUN'),\n",
       " Token(lemma='choose', POS='VERB'),\n",
       " Token(lemma='discuss', POS='VERB'),\n",
       " Token(lemma='mention', POS='VERB'),\n",
       " Token(lemma='propose', POS='VERB'),\n",
       " Token(lemma='excellent', POS='ADJ'),\n",
       " Token(lemma='surface', POS='NOUN'),\n",
       " Token(lemma='popular', POS='ADJ'),\n",
       " Token(lemma='expect', POS='VERB'),\n",
       " Token(lemma='happen', POS='VERB'),\n",
       " Token(lemma='german', POS='ADJ'),\n",
       " Token(lemma='object', POS='NOUN'),\n",
       " Token(lemma='troops', POS='NOUN'),\n",
       " Token(lemma='young', POS='ADJ'),\n",
       " Token(lemma='introduce', POS='VERB'),\n",
       " Token(lemma='dog', POS='NOUN'),\n",
       " Token(lemma='director', POS='NOUN'),\n",
       " Token(lemma='decide', POS='VERB'),\n",
       " Token(lemma='unit', POS='NOUN'),\n",
       " Token(lemma='check', POS='VERB'),\n",
       " Token(lemma='science', POS='NOUN'),\n",
       " Token(lemma='cost', POS='NOUN'),\n",
       " Token(lemma='wait', POS='VERB'),\n",
       " Token(lemma='sea', POS='NOUN'),\n",
       " Token(lemma='solution', POS='NOUN'),\n",
       " Token(lemma='effort', POS='NOUN'),\n",
       " Token(lemma='join', POS='VERB'),\n",
       " Token(lemma='movement', POS='NOUN'),\n",
       " Token(lemma='enter', POS='VERB'),\n",
       " Token(lemma='note', POS='VERB'),\n",
       " Token(lemma='stage', POS='NOUN'),\n",
       " Token(lemma='significant', POS='ADJ'),\n",
       " Token(lemma='application', POS='NOUN'),\n",
       " Token(lemma='atomic', POS='ADJ'),\n",
       " Token(lemma='plan', POS='NOUN'),\n",
       " Token(lemma='drive', POS='VERB'),\n",
       " Token(lemma='appeal', POS='NOUN'),\n",
       " Token(lemma='spend', POS='VERB'),\n",
       " Token(lemma='enjoy', POS='VERB'),\n",
       " Token(lemma='understand', POS='VERB'),\n",
       " Token(lemma='mass', POS='NOUN'),\n",
       " Token(lemma='health', POS='NOUN'),\n",
       " Token(lemma='restaurant', POS='NOUN'),\n",
       " Token(lemma='egg', POS='NOUN'),\n",
       " Token(lemma='engine', POS='NOUN'),\n",
       " Token(lemma='support', POS='NOUN'),\n",
       " Token(lemma='bit', POS='NOUN'),\n",
       " Token(lemma='media', POS='NOUN'),\n",
       " Token(lemma='fall', POS='VERB'),\n",
       " Token(lemma='subject', POS='NOUN'),\n",
       " Token(lemma='reduce', POS='VERB'),\n",
       " Token(lemma='store', POS='NOUN'),\n",
       " Token(lemma='carry', POS='VERB'),\n",
       " Token(lemma='third', POS='ADJ'),\n",
       " Token(lemma='indicate', POS='VERB'),\n",
       " Token(lemma='rule', POS='NOUN'),\n",
       " Token(lemma='care', POS='NOUN'),\n",
       " Token(lemma='activity', POS='NOUN'),\n",
       " Token(lemma='technique', POS='NOUN'),\n",
       " Token(lemma='province', POS='NOUN'),\n",
       " Token(lemma='method', POS='NOUN'),\n",
       " Token(lemma='article', POS='NOUN'),\n",
       " Token(lemma='higher', POS='ADJ'),\n",
       " Token(lemma='material', POS='NOUN'),\n",
       " Token(lemma='father', POS='NOUN'),\n",
       " Token(lemma='replace', POS='VERB'),\n",
       " Token(lemma='charge', POS='VERB'),\n",
       " Token(lemma='argue', POS='VERB'),\n",
       " Token(lemma='organization', POS='NOUN'),\n",
       " Token(lemma='variety', POS='NOUN'),\n",
       " Token(lemma='plan', POS='VERB'),\n",
       " Token(lemma='evidence', POS='NOUN'),\n",
       " Token(lemma='agree', POS='VERB'),\n",
       " Token(lemma='fight', POS='VERB'),\n",
       " Token(lemma='explain', POS='VERB'),\n",
       " Token(lemma='town', POS='NOUN'),\n",
       " Token(lemma='basis', POS='NOUN'),\n",
       " Token(lemma='discover', POS='VERB'),\n",
       " Token(lemma='apply', POS='VERB'),\n",
       " Token(lemma='treat', POS='VERB'),\n",
       " Token(lemma='view', POS='NOUN'),\n",
       " Token(lemma='alkali', POS='ADJ'),\n",
       " Token(lemma='big', POS='ADJ'),\n",
       " Token(lemma='response', POS='NOUN'),\n",
       " Token(lemma='wife', POS='NOUN'),\n",
       " Token(lemma='southern', POS='ADJ'),\n",
       " Token(lemma='present', POS='ADJ'),\n",
       " Token(lemma='rights', POS='NOUN'),\n",
       " Token(lemma='tax', POS='NOUN'),\n",
       " Token(lemma='condition', POS='NOUN'),\n",
       " Token(lemma='associate', POS='VERB'),\n",
       " Token(lemma='temperature', POS='NOUN'),\n",
       " Token(lemma='nation', POS='NOUN'),\n",
       " Token(lemma='defeat', POS='VERB'),\n",
       " Token(lemma='open', POS='VERB'),\n",
       " Token(lemma='nuclear', POS='ADJ'),\n",
       " Token(lemma='right', POS='ADJ'),\n",
       " Token(lemma='recent', POS='ADJ'),\n",
       " Token(lemma='addition', POS='NOUN'),\n",
       " Token(lemma='perform', POS='VERB'),\n",
       " Token(lemma='learn', POS='VERB'),\n",
       " Token(lemma='cover', POS='VERB'),\n",
       " Token(lemma='magnitude', POS='NOUN'),\n",
       " Token(lemma='confederate', POS='ADJ'),\n",
       " Token(lemma='nucleus', POS='NOUN'),\n",
       " Token(lemma='low', POS='ADJ'),\n",
       " Token(lemma='stop', POS='VERB'),\n",
       " Token(lemma='charge', POS='NOUN'),\n",
       " Token(lemma='professional', POS='ADJ'),\n",
       " Token(lemma='standard', POS='NOUN'),\n",
       " Token(lemma='animation', POS='NOUN'),\n",
       " Token(lemma='research', POS='NOUN'),\n",
       " Token(lemma='operation', POS='NOUN'),\n",
       " Token(lemma='message', POS='NOUN'),\n",
       " Token(lemma='whole', POS='ADJ'),\n",
       " Token(lemma='option', POS='NOUN'),\n",
       " Token(lemma='meaning', POS='NOUN'),\n",
       " Token(lemma='larger', POS='ADJ'),\n",
       " Token(lemma='policy', POS='NOUN'),\n",
       " Token(lemma='french', POS='ADJ'),\n",
       " Token(lemma='risk', POS='NOUN'),\n",
       " Token(lemma='capital', POS='NOUN'),\n",
       " Token(lemma='range', POS='NOUN'),\n",
       " Token(lemma='seek', POS='VERB'),\n",
       " Token(lemma='link', POS='NOUN'),\n",
       " Token(lemma='statement', POS='NOUN'),\n",
       " Token(lemma='involve', POS='VERB'),\n",
       " Token(lemma='central', POS='ADJ'),\n",
       " Token(lemma='half', POS='NOUN'),\n",
       " Token(lemma='black', POS='ADJ'),\n",
       " Token(lemma='ion', POS='NOUN'),\n",
       " Token(lemma='peace', POS='NOUN'),\n",
       " Token(lemma='self', POS='NOUN'),\n",
       " Token(lemma='cell', POS='NOUN'),\n",
       " Token(lemma='size', POS='NOUN'),\n",
       " Token(lemma='top', POS='ADJ'),\n",
       " Token(lemma='couple', POS='NOUN'),\n",
       " Token(lemma='economic', POS='ADJ'),\n",
       " Token(lemma='student', POS='NOUN'),\n",
       " Token(lemma='sign', POS='VERB'),\n",
       " Token(lemma='function', POS='NOUN'),\n",
       " Token(lemma='percentage', POS='NOUN'),\n",
       " Token(lemma='reaction', POS='NOUN'),\n",
       " Token(lemma='entire', POS='ADJ'),\n",
       " Token(lemma='girl', POS='NOUN'),\n",
       " Token(lemma='treatment', POS='NOUN'),\n",
       " Token(lemma='test', POS='NOUN'),\n",
       " Token(lemma='white', POS='ADJ'),\n",
       " Token(lemma='economy', POS='NOUN'),\n",
       " Token(lemma='maintain', POS='VERB'),\n",
       " Token(lemma='derive', POS='VERB'),\n",
       " Token(lemma='present', POS='VERB'),\n",
       " Token(lemma='relate', POS='VERB'),\n",
       " Token(lemma='user', POS='NOUN'),\n",
       " Token(lemma='base', POS='NOUN'),\n",
       " Token(lemma='role', POS='NOUN'),\n",
       " Token(lemma='order', POS='VERB'),\n",
       " Token(lemma='ship', POS='NOUN'),\n",
       " Token(lemma='particle', POS='NOUN'),\n",
       " Token(lemma='raise', POS='VERB'),\n",
       " Token(lemma='kind', POS='NOUN'),\n",
       " Token(lemma='mother', POS='NOUN'),\n",
       " Token(lemma='record', POS='NOUN'),\n",
       " Token(lemma='compound', POS='NOUN'),\n",
       " Token(lemma='aluminium', POS='NOUN'),\n",
       " Token(lemma='table', POS='NOUN'),\n",
       " Token(lemma='close', POS='ADJ'),\n",
       " Token(lemma='copy', POS='NOUN'),\n",
       " Token(lemma='fish', POS='NOUN'),\n",
       " Token(lemma='less', POS='ADJ'),\n",
       " Token(lemma='attempt', POS='NOUN'),\n",
       " Token(lemma='egyptian', POS='ADJ'),\n",
       " Token(lemma='parent', POS='NOUN'),\n",
       " Token(lemma='consist', POS='VERB'),\n",
       " Token(lemma='prove', POS='VERB'),\n",
       " Token(lemma='crew', POS='NOUN'),\n",
       " Token(lemma='depend', POS='VERB'),\n",
       " Token(lemma='act', POS='VERB'),\n",
       " Token(lemma='difference', POS='NOUN'),\n",
       " Token(lemma='special', POS='ADJ'),\n",
       " Token(lemma='image', POS='NOUN'),\n",
       " Token(lemma='refuse', POS='VERB'),\n",
       " Token(lemma='global', POS='ADJ'),\n",
       " Token(lemma='industry', POS='NOUN'),\n",
       " Token(lemma='announce', POS='VERB'),\n",
       " Token(lemma='place', POS='VERB'),\n",
       " Token(lemma='picture', POS='NOUN'),\n",
       " Token(lemma='current', POS='ADJ'),\n",
       " Token(lemma='capture', POS='VERB'),\n",
       " Token(lemma='stable', POS='ADJ'),\n",
       " Token(lemma='traditional', POS='ADJ'),\n",
       " Token(lemma='proton', POS='NOUN'),\n",
       " Token(lemma='consonant', POS='NOUN'),\n",
       " Token(lemma='authority', POS='NOUN'),\n",
       " Token(lemma='community', POS='NOUN'),\n",
       " Token(lemma='comment', POS='NOUN'),\n",
       " Token(lemma='japanese', POS='ADJ'),\n",
       " Token(lemma='foreign', POS='ADJ'),\n",
       " Token(lemma='security', POS='NOUN'),\n",
       " Token(lemma='help', POS='NOUN'),\n",
       " Token(lemma='owner', POS='NOUN'),\n",
       " Token(lemma='walk', POS='VERB'),\n",
       " Token(lemma='career', POS='NOUN'),\n",
       " Token(lemma='isotope', POS='NOUN'),\n",
       " Token(lemma='intend', POS='VERB'),\n",
       " Token(lemma='remove', POS='VERB'),\n",
       " Token(lemma='personal', POS='ADJ'),\n",
       " Token(lemma='prepare', POS='VERB'),\n",
       " Token(lemma='aircraft', POS='NOUN'),\n",
       " Token(lemma='practice', POS='NOUN'),\n",
       " Token(lemma='weapon', POS='NOUN'),\n",
       " Token(lemma='feature', POS='NOUN'),\n",
       " Token(lemma='break', POS='VERB'),\n",
       " Token(lemma='situation', POS='NOUN'),\n",
       " Token(lemma='mind', POS='NOUN'),\n",
       " Token(lemma='north', POS='NOUN'),\n",
       " Token(lemma='identify', POS='VERB'),\n",
       " Token(lemma='symbol', POS='NOUN'),\n",
       " Token(lemma='launch', POS='VERB'),\n",
       " Token(lemma='determine', POS='VERB'),\n",
       " Token(lemma='specific', POS='ADJ'),\n",
       " Token(lemma='total', POS='ADJ'),\n",
       " Token(lemma='rest', POS='NOUN'),\n",
       " Token(lemma='compare', POS='VERB'),\n",
       " Token(lemma='medical', POS='ADJ'),\n",
       " Token(lemma='south', POS='NOUN'),\n",
       " Token(lemma='player', POS='NOUN'),\n",
       " Token(lemma='right', POS='NOUN'),\n",
       " Token(lemma='open', POS='ADJ'),\n",
       " Token(lemma='attend', POS='VERB'),\n",
       " Token(lemma='draft', POS='NOUN'),\n",
       " Token(lemma='least', POS='ADJ'),\n",
       " Token(lemma='flight', POS='NOUN'),\n",
       " Token(lemma='website', POS='NOUN'),\n",
       " Token(lemma='hard', POS='ADJ'),\n",
       " Token(lemma='indian', POS='ADJ'),\n",
       " Token(lemma='pair', POS='NOUN'),\n",
       " Token(lemma='federal', POS='ADJ'),\n",
       " Token(lemma='remember', POS='VERB'),\n",
       " Token(lemma='sense', POS='NOUN'),\n",
       " Token(lemma='private', POS='ADJ'),\n",
       " Token(lemma='stand', POS='VERB'),\n",
       " Token(lemma='contract', POS='NOUN'),\n",
       " Token(lemma='president', POS='NOUN'),\n",
       " Token(lemma='matter', POS='NOUN'),\n",
       " Token(lemma='summer', POS='NOUN'),\n",
       " Token(lemma='agent', POS='NOUN'),\n",
       " Token(lemma='travel', POS='VERB'),\n",
       " Token(lemma='arrive', POS='VERB'),\n",
       " Token(lemma='fail', POS='VERB'),\n",
       " Token(lemma='eye', POS='NOUN'),\n",
       " Token(lemma='fix', POS='VERB'),\n",
       " Token(lemma='majority', POS='NOUN'),\n",
       " Token(lemma='match', POS='NOUN'),\n",
       " Token(lemma='relationship', POS='NOUN'),\n",
       " Token(lemma='section', POS='NOUN'),\n",
       " Token(lemma='physical', POS='ADJ'),\n",
       " Token(lemma='else', POS='ADJ'),\n",
       " Token(lemma='civil', POS='ADJ'),\n",
       " Token(lemma='recognize', POS='VERB'),\n",
       " Token(lemma='video', POS='NOUN'),\n",
       " Token(lemma='song', POS='NOUN'),\n",
       " Token(lemma='philosophy', POS='NOUN'),\n",
       " Token(lemma='enough', POS='ADJ'),\n",
       " Token(lemma='religious', POS='ADJ'),\n",
       " Token(lemma='estimate', POS='VERB'),\n",
       " Token(lemma='writer', POS='NOUN'),\n",
       " Token(lemma='administration', POS='NOUN'),\n",
       " Token(lemma='happy', POS='ADJ'),\n",
       " Token(lemma='control', POS='VERB'),\n",
       " Token(lemma='need', POS='NOUN'),\n",
       " Token(lemma='numerous', POS='ADJ'),\n",
       " Token(lemma='hotel', POS='NOUN'),\n",
       " Token(lemma='study', POS='VERB'),\n",
       " Token(lemma='education', POS='NOUN'),\n",
       " Token(lemma='nature', POS='NOUN'),\n",
       " Token(lemma='artist', POS='NOUN'),\n",
       " Token(lemma='figure', POS='NOUN'),\n",
       " Token(lemma='independent', POS='ADJ'),\n",
       " Token(lemma='cultural', POS='ADJ'),\n",
       " Token(lemma='feature', POS='VERB'),\n",
       " Token(lemma='clear', POS='ADJ'),\n",
       " Token(lemma='lack', POS='NOUN'),\n",
       " Token(lemma='hair', POS='NOUN'),\n",
       " Token(lemma='loss', POS='NOUN'),\n",
       " Token(lemma='assume', POS='VERB'),\n",
       " Token(lemma='feed', POS='VERB'),\n",
       " Token(lemma='status', POS='NOUN'),\n",
       " Token(lemma='slavery', POS='NOUN'),\n",
       " Token(lemma='algorithm', POS='NOUN'),\n",
       " Token(lemma='official', POS='NOUN'),\n",
       " Token(lemma='employee', POS='NOUN'),\n",
       " Token(lemma='piece', POS='NOUN'),\n",
       " Token(lemma='love', POS='NOUN'),\n",
       " Token(lemma='back', POS='NOUN'),\n",
       " Token(lemma='detail', POS='NOUN'),\n",
       " Token(lemma='share', POS='VERB'),\n",
       " Token(lemma='bird', POS='NOUN'),\n",
       " Token(lemma='helpful', POS='ADJ'),\n",
       " Token(lemma='poor', POS='ADJ'),\n",
       " Token(lemma='step', POS='NOUN'),\n",
       " Token(lemma='difficult', POS='ADJ'),\n",
       " Token(lemma='sound', POS='NOUN'),\n",
       " Token(lemma='later', POS='ADJ'),\n",
       " Token(lemma='environment', POS='NOUN'),\n",
       " Token(lemma='suffer', POS='VERB'),\n",
       " Token(lemma='morning', POS='NOUN'),\n",
       " Token(lemma='training', POS='NOUN'),\n",
       " Token(lemma='force', POS='VERB'),\n",
       " Token(lemma='color', POS='NOUN'),\n",
       " Token(lemma='tradition', POS='NOUN'),\n",
       " Token(lemma='observe', POS='VERB'),\n",
       " Token(lemma='influence', POS='NOUN'),\n",
       " Token(lemma='society', POS='NOUN'),\n",
       " Token(lemma='greater', POS='ADJ'),\n",
       " Token(lemma='growth', POS='NOUN'),\n",
       " Token(lemma='direct', POS='ADJ'),\n",
       " Token(lemma='clean', POS='ADJ'),\n",
       " Token(lemma='reflect', POS='VERB'),\n",
       " Token(lemma='official', POS='ADJ'),\n",
       " Token(lemma='building', POS='NOUN'),\n",
       " Token(lemma='season', POS='NOUN'),\n",
       " Token(lemma='design', POS='NOUN'),\n",
       " Token(lemma='lunar', POS='ADJ'),\n",
       " Token(lemma='means', POS='NOUN'),\n",
       " Token(lemma='separate', POS='VERB'),\n",
       " Token(lemma='oppose', POS='VERB'),\n",
       " Token(lemma='successful', POS='ADJ'),\n",
       " Token(lemma='simple', POS='ADJ'),\n",
       " Token(lemma='northern', POS='ADJ'),\n",
       " Token(lemma='daughter', POS='NOUN'),\n",
       " Token(lemma='success', POS='NOUN'),\n",
       " Token(lemma='fine', POS='ADJ'),\n",
       " Token(lemma='argument', POS='NOUN'),\n",
       " Token(lemma='credit', POS='NOUN'),\n",
       " Token(lemma='sale', POS='NOUN'),\n",
       " Token(lemma='focus', POS='VERB'),\n",
       " Token(lemma='trial', POS='NOUN'),\n",
       " Token(lemma='band', POS='NOUN'),\n",
       " Token(lemma='king', POS='NOUN'),\n",
       " Token(lemma='record', POS='VERB'),\n",
       " Token(lemma='vary', POS='VERB'),\n",
       " Token(lemma='individual', POS='NOUN'),\n",
       " Token(lemma='dollar', POS='NOUN'),\n",
       " Token(lemma='face', POS='VERB'),\n",
       " Token(lemma='rank', POS='VERB'),\n",
       " Token(lemma='concern', POS='NOUN'),\n",
       " Token(lemma='arm', POS='NOUN'),\n",
       " Token(lemma='degree', POS='NOUN'),\n",
       " Token(lemma='achieve', POS='VERB'),\n",
       " Token(lemma='european', POS='ADJ'),\n",
       " Token(lemma='asteroid', POS='NOUN'),\n",
       " Token(lemma='soldier', POS='NOUN'),\n",
       " Token(lemma='item', POS='NOUN'),\n",
       " Token(lemma='answer', POS='NOUN'),\n",
       " Token(lemma='principle', POS='NOUN'),\n",
       " Token(lemma='handle', POS='VERB'),\n",
       " Token(lemma='prevent', POS='VERB'),\n",
       " Token(lemma='watch', POS='VERB'),\n",
       " Token(lemma='additional', POS='ADJ'),\n",
       " Token(lemma='request', POS='NOUN'),\n",
       " Token(lemma='easy', POS='ADJ'),\n",
       " Token(lemma='account', POS='NOUN'),\n",
       " Token(lemma='smaller', POS='ADJ'),\n",
       " Token(lemma='god', POS='NOUN'),\n",
       " Token(lemma='separate', POS='ADJ'),\n",
       " Token(lemma='collection', POS='NOUN'),\n",
       " Token(lemma='combine', POS='VERB'),\n",
       " Token(lemma='mission', POS='NOUN'),\n",
       " Token(lemma='factor', POS='NOUN'),\n",
       " Token(lemma='datum', POS='NOUN'),\n",
       " Token(lemma='attack', POS='VERB'),\n",
       " Token(lemma='connection', POS='NOUN'),\n",
       " Token(lemma='express', POS='VERB'),\n",
       " Token(lemma='direction', POS='NOUN'),\n",
       " Token(lemma='interested', POS='ADJ'),\n",
       " Token(lemma='regards', POS='NOUN'),\n",
       " Token(lemma='purpose', POS='NOUN'),\n",
       " Token(lemma='page', POS='NOUN'),\n",
       " Token(lemma='code', POS='NOUN'),\n",
       " Token(lemma='doctor', POS='NOUN'),\n",
       " Token(lemma='religion', POS='NOUN'),\n",
       " Token(lemma='leg', POS='NOUN'),\n",
       " Token(lemma='beginning', POS='NOUN'),\n",
       " Token(lemma='birth', POS='NOUN'),\n",
       " Token(lemma='arsenic', POS='NOUN'),\n",
       " Token(lemma='agricultural', POS='ADJ'),\n",
       " Token(lemma='opinion', POS='NOUN'),\n",
       " Token(lemma='conflict', POS='NOUN'),\n",
       " Token(lemma='conference', POS='NOUN'),\n",
       " Token(lemma='chemical', POS='ADJ'),\n",
       " Token(lemma='scale', POS='NOUN'),\n",
       " Token(lemma='deal', POS='VERB'),\n",
       " Token(lemma='officer', POS='NOUN'),\n",
       " Token(lemma='destroy', POS='VERB'),\n",
       " Token(lemma='human', POS='NOUN'),\n",
       " Token(lemma='complete', POS='VERB'),\n",
       " Token(lemma='declare', POS='VERB'),\n",
       " Token(lemma='tank', POS='NOUN'),\n",
       " Token(lemma='divide', POS='VERB'),\n",
       " Token(lemma='branch', POS='NOUN'),\n",
       " Token(lemma='scholar', POS='NOUN'),\n",
       " Token(lemma='slave', POS='NOUN'),\n",
       " Token(lemma='river', POS='NOUN'),\n",
       " Token(lemma='orbit', POS='NOUN'),\n",
       " Token(lemma='sodium', POS='NOUN'),\n",
       " Token(lemma='goal', POS='NOUN'),\n",
       " Token(lemma='fill', POS='VERB'),\n",
       " Token(lemma='effective', POS='ADJ'),\n",
       " Token(lemma='dead', POS='ADJ'),\n",
       " Token(lemma='confirm', POS='VERB'),\n",
       " Token(lemma='sit', POS='VERB'),\n",
       " Token(lemma='necessary', POS='ADJ'),\n",
       " Token(lemma='front', POS='NOUN'),\n",
       " Token(lemma='attention', POS='NOUN'),\n",
       " Token(lemma='kid', POS='NOUN'),\n",
       " Token(lemma='react', POS='VERB'),\n",
       " Token(lemma='attempt', POS='VERB'),\n",
       " Token(lemma='border', POS='NOUN'),\n",
       " Token(lemma='amazing', POS='ADJ'),\n",
       " Token(lemma='save', POS='VERB'),\n",
       " Token(lemma='decade', POS='NOUN'),\n",
       " Token(lemma='presence', POS='NOUN'),\n",
       " Token(lemma='division', POS='NOUN'),\n",
       " Token(lemma='draw', POS='VERB'),\n",
       " Token(lemma='chinese', POS='ADJ'),\n",
       " Token(lemma='generation', POS='NOUN'),\n",
       " Token(lemma='victory', POS='NOUN'),\n",
       " Token(lemma='obtain', POS='VERB'),\n",
       " Token(lemma='climate', POS='NOUN'),\n",
       " Token(lemma='arabic', POS='ADJ'),\n",
       " Token(lemma='astronomer', POS='NOUN'),\n",
       " Token(lemma='close', POS='VERB'),\n",
       " Token(lemma='survive', POS='VERB'),\n",
       " Token(lemma='extend', POS='VERB'),\n",
       " Token(lemma='access', POS='NOUN'),\n",
       " Token(lemma='review', POS='VERB'),\n",
       " Token(lemma='fly', POS='VERB'),\n",
       " Token(lemma='military', POS='NOUN'),\n",
       " Token(lemma='average', POS='ADJ'),\n",
       " Token(lemma='foot', POS='NOUN'),\n",
       " Token(lemma='door', POS='NOUN'),\n",
       " Token(lemma='purchase', POS='VERB'),\n",
       " Token(lemma='worker', POS='NOUN'),\n",
       " Token(lemma='ground', POS='NOUN'),\n",
       " Token(lemma='dialect', POS='NOUN'),\n",
       " Token(lemma='found', POS='VERB'),\n",
       " Token(lemma='board', POS='NOUN'),\n",
       " Token(lemma='top', POS='NOUN'),\n",
       " Token(lemma='movie', POS='NOUN'),\n",
       " Token(lemma='address', POS='NOUN'),\n",
       " Token(lemma='highest', POS='ADJ'),\n",
       " Token(lemma='news', POS='NOUN'),\n",
       " Token(lemma='date', POS='VERB'),\n",
       " Token(lemma='sign', POS='NOUN'),\n",
       " Token(lemma='standard', POS='ADJ'),\n",
       " Token(lemma='wonderful', POS='ADJ'),\n",
       " Token(lemma='definition', POS='NOUN'),\n",
       " Token(lemma='university', POS='NOUN'),\n",
       " Token(lemma='planet', POS='NOUN'),\n",
       " Token(lemma='east', POS='NOUN'),\n",
       " Token(lemma='course', POS='NOUN'),\n",
       " Token(lemma='hydrogen', POS='NOUN'),\n",
       " Token(lemma='neutron', POS='NOUN'),\n",
       " Token(lemma='police', POS='NOUN'),\n",
       " Token(lemma='chance', POS='NOUN'),\n",
       " Token(lemma='thought', POS='NOUN'),\n",
       " Token(lemma='opportunity', POS='NOUN'),\n",
       " Token(lemma='knowledge', POS='NOUN'),\n",
       " Token(lemma='weekend', POS='NOUN'),\n",
       " Token(lemma='e-mail', POS='NOUN'),\n",
       " Token(lemma='compose', POS='VERB'),\n",
       " Token(lemma='fax', POS='NOUN'),\n",
       " Token(lemma='approve', POS='VERB'),\n",
       " Token(lemma='drop', POS='VERB'),\n",
       " Token(lemma='center', POS='NOUN'),\n",
       " Token(lemma='coast', POS='NOUN'),\n",
       " Token(lemma='return', POS='NOUN'),\n",
       " Token(lemma='astronaut', POS='NOUN'),\n",
       " Token(lemma='famous', POS='ADJ'),\n",
       " Token(lemma='cage', POS='NOUN'),\n",
       " Token(lemma='lay', POS='VERB'),\n",
       " Token(lemma='avoid', POS='VERB'),\n",
       " Token(lemma='direct', POS='VERB'),\n",
       " Token(lemma='settlement', POS='NOUN'),\n",
       " Token(lemma='russian', POS='ADJ'),\n",
       " Token(lemma='circle', POS='NOUN'),\n",
       " Token(lemma='constitution', POS='NOUN'),\n",
       " Token(lemma='decay', POS='NOUN'),\n",
       " Token(lemma='astatine', POS='NOUN'),\n",
       " Token(lemma='root', POS='NOUN'),\n",
       " Token(lemma='post', POS='VERB'),\n",
       " Token(lemma='dinner', POS='NOUN'),\n",
       " Token(lemma='trip', POS='NOUN'),\n",
       " Token(lemma='last', POS='VERB'),\n",
       " Token(lemma='west', POS='NOUN'),\n",
       " Token(lemma='expand', POS='VERB'),\n",
       " Token(lemma='participate', POS='VERB'),\n",
       " Token(lemma='threat', POS='NOUN'),\n",
       " Token(lemma='related', POS='ADJ'),\n",
       " Token(lemma='disease', POS='NOUN'),\n",
       " Token(lemma='award', POS='NOUN'),\n",
       " Token(lemma='19th', POS='ADJ'),\n",
       " Token(lemma='independence', POS='NOUN'),\n",
       " Token(lemma='likely', POS='ADJ'),\n",
       " Token(lemma='protect', POS='VERB'),\n",
       " Token(lemma='internet', POS='NOUN'),\n",
       " Token(lemma='governor', POS='NOUN'),\n",
       " Token(lemma='influence', POS='VERB'),\n",
       " Token(lemma='contact', POS='NOUN'),\n",
       " Token(lemma='winter', POS='NOUN'),\n",
       " Token(lemma='paper', POS='NOUN'),\n",
       " Token(lemma='document', POS='NOUN'),\n",
       " Token(lemma='weight', POS='NOUN'),\n",
       " Token(lemma='facility', POS='NOUN'),\n",
       " Token(lemma='screen', POS='NOUN'),\n",
       " Token(lemma='expensive', POS='ADJ'),\n",
       " Token(lemma='mouth', POS='NOUN'),\n",
       " Token(lemma='relation', POS='NOUN'),\n",
       " Token(lemma='concept', POS='NOUN'),\n",
       " Token(lemma='previous', POS='ADJ'),\n",
       " Token(lemma='internal', POS='ADJ'),\n",
       " Token(lemma='primary', POS='ADJ'),\n",
       " Token(lemma='appellate', POS='ADJ'),\n",
       " Token(lemma='eastern', POS='ADJ'),\n",
       " Token(lemma='act', POS='NOUN'),\n",
       " Token(lemma='bus', POS='NOUN'),\n",
       " Token(lemma='elect', POS='VERB'),\n",
       " Token(lemma='note', POS='NOUN'),\n",
       " Token(lemma='financial', POS='ADJ'),\n",
       " Token(lemma='cut', POS='VERB'),\n",
       " Token(lemma='prior', POS='ADJ'),\n",
       " Token(lemma='round', POS='NOUN'),\n",
       " Token(lemma='pick', POS='VERB'),\n",
       " Token(lemma='male', POS='NOUN'),\n",
       " Token(lemma='vote', POS='VERB'),\n",
       " Token(lemma='blood', POS='NOUN'),\n",
       " Token(lemma='atmosphere', POS='NOUN'),\n",
       " Token(lemma='shop', POS='NOUN'),\n",
       " Token(lemma='management', POS='NOUN'),\n",
       " Token(lemma='pressure', POS='NOUN'),\n",
       " Token(lemma='tour', POS='NOUN'),\n",
       " Token(lemma='reject', POS='VERB'),\n",
       " Token(lemma='affect', POS='VERB'),\n",
       " Token(lemma='operate', POS='VERB'),\n",
       " Token(lemma='speaker', POS='NOUN'),\n",
       " Token(lemma='ability', POS='NOUN'),\n",
       " Token(lemma='percent', POS='NOUN'),\n",
       " Token(lemma='albanian', POS='ADJ'),\n",
       " Token(lemma='trade', POS='NOUN'),\n",
       " Token(lemma='turkish', POS='ADJ'),\n",
       " Token(lemma='farm', POS='NOUN'),\n",
       " Token(lemma='empire', POS='NOUN'),\n",
       " Token(lemma='camera', POS='NOUN'),\n",
       " Token(lemma='exception', POS='NOUN'),\n",
       " Token(lemma='analysis', POS='NOUN'),\n",
       " Token(lemma='constellation', POS='NOUN'),\n",
       " Token(lemma='wrong', POS='ADJ'),\n",
       " Token(lemma='distance', POS='NOUN'),\n",
       " Token(lemma='origin', POS='NOUN'),\n",
       " Token(lemma='mountain', POS='NOUN'),\n",
       " Token(lemma='pet', POS='NOUN'),\n",
       " Token(lemma='deliver', POS='VERB'),\n",
       " Token(lemma='resource', POS='NOUN'),\n",
       " Token(lemma='active', POS='ADJ'),\n",
       " Token(lemma='scientist', POS='NOUN'),\n",
       " Token(lemma='frog', POS='NOUN'),\n",
       " Token(lemma='literature', POS='NOUN'),\n",
       " Token(lemma='design', POS='VERB'),\n",
       " Token(lemma='novel', POS='NOUN'),\n",
       " Token(lemma='latin', POS='ADJ'),\n",
       " Token(lemma='salt', POS='NOUN'),\n",
       " Token(lemma='stock', POS='NOUN'),\n",
       " Token(lemma='ad', POS='NOUN'),\n",
       " Token(lemma='huge', POS='ADJ'),\n",
       " Token(lemma='citizen', POS='NOUN'),\n",
       " Token(lemma='serious', POS='ADJ'),\n",
       " Token(lemma='realize', POS='VERB'),\n",
       " Token(lemma='vehicle', POS='NOUN'),\n",
       " Token(lemma='promote', POS='VERB'),\n",
       " Token(lemma='rise', POS='VERB'),\n",
       " Token(lemma='face', POS='NOUN'),\n",
       " Token(lemma='improve', POS='VERB'),\n",
       " Token(lemma='initial', POS='ADJ'),\n",
       " Token(lemma='tend', POS='VERB'),\n",
       " Token(lemma='institution', POS='NOUN'),\n",
       " Token(lemma='tv', POS='NOUN'),\n",
       " Token(lemma='formal', POS='ADJ'),\n",
       " Token(lemma='command', POS='NOUN'),\n",
       " Token(lemma='television', POS='NOUN'),\n",
       " Token(lemma='request', POS='VERB'),\n",
       " Token(lemma='correspond', POS='VERB'),\n",
       " Token(lemma='jurisdiction', POS='NOUN'),\n",
       " Token(lemma='spacecraft', POS='NOUN'),\n",
       " Token(lemma='length', POS='NOUN'),\n",
       " Token(lemma='telescope', POS='NOUN'),\n",
       " Token(lemma='murder', POS='NOUN'),\n",
       " Token(lemma='future', POS='ADJ'),\n",
       " Token(lemma='execute', POS='VERB'),\n",
       " Token(lemma='crop', POS='NOUN'),\n",
       " Token(lemma='key', POS='ADJ'),\n",
       " Token(lemma='limited', POS='ADJ'),\n",
       " Token(lemma='fresh', POS='ADJ'),\n",
       " Token(lemma='basic', POS='ADJ'),\n",
       " Token(lemma='train', POS='VERB'),\n",
       " Token(lemma='manager', POS='NOUN'),\n",
       " Token(lemma='select', POS='VERB'),\n",
       " Token(lemma='philosopher', POS='NOUN'),\n",
       " Token(lemma='tribe', POS='NOUN'),\n",
       " Token(lemma='surround', POS='VERB'),\n",
       " Token(lemma='known', POS='ADJ'),\n",
       " Token(lemma='20th', POS='ADJ'),\n",
       " Token(lemma='cause', POS='NOUN'),\n",
       " Token(lemma='english', POS='ADJ'),\n",
       " Token(lemma='no.', POS='NOUN'),\n",
       " Token(lemma='skin', POS='NOUN'),\n",
       " Token(lemma='potassium', POS='NOUN'),\n",
       " Token(lemma='judge', POS='NOUN'),\n",
       " Token(lemma='fire', POS='NOUN'),\n",
       " Token(lemma='responsible', POS='ADJ'),\n",
       " Token(lemma='procedure', POS='NOUN'),\n",
       " Token(lemma='marry', POS='VERB'),\n",
       " Token(lemma='acquire', POS='VERB'),\n",
       " Token(lemma='software', POS='NOUN'),\n",
       " Token(lemma='x', POS='NOUN'),\n",
       " Token(lemma='reference', POS='NOUN'),\n",
       " Token(lemma='list', POS='VERB'),\n",
       " Token(lemma='claim', POS='NOUN'),\n",
       " Token(lemma='multiple', POS='ADJ'),\n",
       " Token(lemma='assist', POS='VERB'),\n",
       " Token(lemma='green', POS='ADJ'),\n",
       " Token(lemma='soil', POS='NOUN'),\n",
       " Token(lemma='critical', POS='ADJ'),\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vocabulary._index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-implement",
   "metadata": {},
   "source": [
    "### Context "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-public",
   "metadata": {},
   "source": [
    "#### Option 1: consider dependency relation  as undirected by setting directed parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unlikely-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency_context = mangoes.context.DependencyBasedContext(entity=(\"lemma\",\"POS\"), \n",
    "#                                                             labels=True,\n",
    "#                                                             collapse=True, \n",
    "#                                                             vocabulary=context_vocabulary,\n",
    "#                                                             directed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-harassment",
   "metadata": {},
   "source": [
    "#### Option 2: consider only dependency relation of \"advmod\" or \"nsubj\"\n",
    "Note if collapse is set to True, then case will be included as well. \n",
    "\n",
    "\n",
    "This will result in changed number of context words when co-occurrence matrix is built "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "experienced-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency_context = mangoes.context.DependencyBasedContext(entity=(\"lemma\",\"POS\"), \n",
    "#                                                             labels=True,\n",
    "#                                                             collapse=True, \n",
    "#                                                             vocabulary=context_vocabulary,\n",
    "#                                                             deprel_keep = (\"advmod\", \"nsubj\"),\n",
    "#                                                             directed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-yield",
   "metadata": {},
   "source": [
    "#### Option 3 adding depth to consider indirected dependency relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "signal-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependency_context = mangoes.context.DependencyBasedContext(entity=(\"lemma\",\"POS\"), \n",
    "#                                                             labels=True,\n",
    "#                                                             collapse=True, \n",
    "#                                                             vocabulary=context_vocabulary,\n",
    "#                                                             directed=False,\n",
    "#                                                             depth=2\n",
    "#                                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-headline",
   "metadata": {},
   "source": [
    "#### Option 4: Combining option 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-gazette",
   "metadata": {},
   "source": [
    "If `depth` > 1 and `deprel_keep` is specified then `deprel_keep` will be counted as long as indirected dependency relations has one relation from `deprel_keep`.\n",
    "\n",
    "\n",
    "eg. If `depth=2` and `deprel_keep=(\"nsubj\")` then  `{'lemma': 'muslim', 'POS': 'ADJ'}/nsubj_amod\",` will be included as context words since one of the dependency relation `nsubj` is in `deprel_keep`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "convertible-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_context = mangoes.context.DependencyBasedContext(entity=(\"lemma\",\"POS\"), \n",
    "                                                            labels=True,\n",
    "                                                            collapse=True, \n",
    "                                                            vocabulary=context_vocabulary,\n",
    "                                                            directed=False,\n",
    "                                                            deprel_keep=(\"advmod\", \"nsubj\"),\n",
    "                                                            depth=2\n",
    "                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "progressive-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save vocabularies \n",
    "# target_vocabulary_file_name = \"vocabulary_{}_target_words\".format(len(target_vocabulary))\n",
    "# context_vocabulary_file_name = \"vocabulary_{}_context_words\".format(len(context_vocabulary))\n",
    "\n",
    "# or load by specify saved vocabulary files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "solved-cardiff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # save\n",
    "# target_vocabulary.save(OUTPUT_PATH, name=target_vocabulary_file_name)\n",
    "# context_vocabulary.save(OUTPUT_PATH, name=context_vocabulary_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "driven-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabs\n",
    "# target_vocabulary = mangoes.Vocabulary.load(\"output\", target_vocabulary_file_name)\n",
    "# context_vocabulary = mangoes.Vocabulary.load(\"output\", context_vocabulary_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-melissa",
   "metadata": {},
   "source": [
    "### Cooccurrence Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hungarian-massachusetts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Unable to parse token Token(id='21', form='it', lemma='it', POS='PRON', xpostag='PRP', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='22', form='pours', lemma='pour', POS='VERB', xpostag='VBZ', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='23', form='water', lemma='water', POS='NOUN', xpostag='NN', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='24', form='in', lemma='in', POS='ADP', xpostag='IN', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='25', form='a', lemma='a', POS='DET', xpostag='DT', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='26', form='stream', lemma='stream', POS='NOUN', xpostag='NN', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='27', form='of', lemma='of', POS='ADP', xpostag='IN', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='28', form='more', lemma='more', POS='ADJ', xpostag='JJR', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='29', form='than', lemma='than', POS='ADP', xpostag='IN', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='30', form='20', lemma='20', POS='NUM', xpostag='CD', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='31', form='stars', lemma='star', POS='NOUN', xpostag='NNS', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='32', form='terminating', lemma='terminate', POS='VERB', xpostag='VBG', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='33', form='with', lemma='with', POS='ADP', xpostag='IN', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='34', form='fomalhaut', lemma='Fomalhaut', POS='PROPN', xpostag='NNP', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='36', form='now', lemma='now', POS='ADV', xpostag='RB', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='37', form='assigned', lemma='assign', POS='VERB', xpostag='VBN', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='38', form='solely', lemma='solely', POS='ADV', xpostag='RB', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='39', form='to', lemma='to', POS='ADP', xpostag='IN', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='40', form='piscis', lemma='Piscis', POS='PROPN', xpostag='NNP', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n",
      "WARNING:root:Unable to parse token Token(id='41', form='austrinus', lemma='Austrinus', POS='PROPN', xpostag='NNP', feats='_', head='_', dependency_relation='_', deps='_', misc='_') in sentence his water jar , an asterism itself , consists of gamma , pi , eta , and zeta aquarii ; it pours water in a stream of more than 20 stars terminating with fomalhaut , now assigned solely to piscis austrinus . (ValueError)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>{'lemma': 'detonate', 'POS': 'VERB'}/nsubj</th>\n",
       "      <th>{'lemma': 'guerrilla', 'POS': 'NOUN'}/nsubj</th>\n",
       "      <th>{'lemma': 'hope', 'POS': 'VERB'}/advcl_nsubj</th>\n",
       "      <th>{'lemma': 'tradeoff', 'POS': 'NOUN'}/nsubj</th>\n",
       "      <th>{'lemma': 'move', 'POS': 'NOUN'}/nsubj</th>\n",
       "      <th>{'lemma': 'suckup', 'POS': 'NOUN'}/acl_nsubj</th>\n",
       "      <th>{'lemma': 'people', 'POS': 'NOUN'}/conj_nsubj</th>\n",
       "      <th>{'lemma': 'suckup', 'POS': 'NOUN'}/nsubj</th>\n",
       "      <th>{'lemma': 'people', 'POS': 'NOUN'}/nsubj</th>\n",
       "      <th>{'lemma': 'remain', 'POS': 'VERB'}/nsubj_amod</th>\n",
       "      <th>...</th>\n",
       "      <th>{'lemma': 'attack', 'POS': 'NOUN'}/conj_nsubj</th>\n",
       "      <th>{'lemma': 'derive', 'POS': 'VERB'}/nsubj_case_of</th>\n",
       "      <th>{'lemma': 'story', 'POS': 'NOUN'}/nsubj_case_of</th>\n",
       "      <th>{'lemma': 'usage', 'POS': 'NOUN'}/conj_nsubj</th>\n",
       "      <th>{'lemma': 'boethius', 'POS': 'NOUN'}/nsubj</th>\n",
       "      <th>{'lemma': 'translate', 'POS': 'VERB'}/conj_nsubj</th>\n",
       "      <th>{'lemma': 'fact', 'POS': 'NOUN'}/nsubj_case_of</th>\n",
       "      <th>{'lemma': 'formalist', 'POS': 'ADJ'}/nsubj_amod</th>\n",
       "      <th>{'lemma': 'truth', 'POS': 'NOUN'}/acl:relcl_nsubj</th>\n",
       "      <th>{'lemma': 'statement', 'POS': 'NOUN'}/acl:relcl_nsubj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attack</th>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social</th>\n",
       "      <th>ADJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <th>ADJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>punch</th>\n",
       "      <th>VERB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursery</th>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rhyme</th>\n",
       "      <th>NOUN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>axiomatize</th>\n",
       "      <th>VERB</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>formalist</th>\n",
       "      <th>ADJ</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11077 rows × 15597 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 {'lemma': 'detonate', 'POS': 'VERB'}/nsubj  \\\n",
       "story      NOUN                                           0   \n",
       "attack     NOUN                                           0   \n",
       "social     ADJ                                            0   \n",
       "bad        ADJ                                            0   \n",
       "market     NOUN                                           0   \n",
       "...                                                     ...   \n",
       "punch      VERB                                           0   \n",
       "nursery    NOUN                                           0   \n",
       "rhyme      NOUN                                           0   \n",
       "axiomatize VERB                                           0   \n",
       "formalist  ADJ                                            0   \n",
       "\n",
       "                 {'lemma': 'guerrilla', 'POS': 'NOUN'}/nsubj  \\\n",
       "story      NOUN                                            0   \n",
       "attack     NOUN                                            0   \n",
       "social     ADJ                                             0   \n",
       "bad        ADJ                                             0   \n",
       "market     NOUN                                            0   \n",
       "...                                                      ...   \n",
       "punch      VERB                                            0   \n",
       "nursery    NOUN                                            0   \n",
       "rhyme      NOUN                                            0   \n",
       "axiomatize VERB                                            0   \n",
       "formalist  ADJ                                             0   \n",
       "\n",
       "                 {'lemma': 'hope', 'POS': 'VERB'}/advcl_nsubj  \\\n",
       "story      NOUN                                             0   \n",
       "attack     NOUN                                             0   \n",
       "social     ADJ                                              0   \n",
       "bad        ADJ                                              0   \n",
       "market     NOUN                                             0   \n",
       "...                                                       ...   \n",
       "punch      VERB                                             0   \n",
       "nursery    NOUN                                             0   \n",
       "rhyme      NOUN                                             0   \n",
       "axiomatize VERB                                             0   \n",
       "formalist  ADJ                                              0   \n",
       "\n",
       "                 {'lemma': 'tradeoff', 'POS': 'NOUN'}/nsubj  \\\n",
       "story      NOUN                                           0   \n",
       "attack     NOUN                                           0   \n",
       "social     ADJ                                            0   \n",
       "bad        ADJ                                            0   \n",
       "market     NOUN                                           0   \n",
       "...                                                     ...   \n",
       "punch      VERB                                           0   \n",
       "nursery    NOUN                                           0   \n",
       "rhyme      NOUN                                           0   \n",
       "axiomatize VERB                                           0   \n",
       "formalist  ADJ                                            0   \n",
       "\n",
       "                 {'lemma': 'move', 'POS': 'NOUN'}/nsubj  \\\n",
       "story      NOUN                                       0   \n",
       "attack     NOUN                                       0   \n",
       "social     ADJ                                        0   \n",
       "bad        ADJ                                        0   \n",
       "market     NOUN                                       0   \n",
       "...                                                 ...   \n",
       "punch      VERB                                       0   \n",
       "nursery    NOUN                                       0   \n",
       "rhyme      NOUN                                       0   \n",
       "axiomatize VERB                                       0   \n",
       "formalist  ADJ                                        0   \n",
       "\n",
       "                 {'lemma': 'suckup', 'POS': 'NOUN'}/acl_nsubj  \\\n",
       "story      NOUN                                             0   \n",
       "attack     NOUN                                             0   \n",
       "social     ADJ                                              0   \n",
       "bad        ADJ                                              0   \n",
       "market     NOUN                                             0   \n",
       "...                                                       ...   \n",
       "punch      VERB                                             0   \n",
       "nursery    NOUN                                             0   \n",
       "rhyme      NOUN                                             0   \n",
       "axiomatize VERB                                             0   \n",
       "formalist  ADJ                                              0   \n",
       "\n",
       "                 {'lemma': 'people', 'POS': 'NOUN'}/conj_nsubj  \\\n",
       "story      NOUN                                              0   \n",
       "attack     NOUN                                              0   \n",
       "social     ADJ                                               0   \n",
       "bad        ADJ                                               0   \n",
       "market     NOUN                                              0   \n",
       "...                                                        ...   \n",
       "punch      VERB                                              0   \n",
       "nursery    NOUN                                              0   \n",
       "rhyme      NOUN                                              0   \n",
       "axiomatize VERB                                              0   \n",
       "formalist  ADJ                                               0   \n",
       "\n",
       "                 {'lemma': 'suckup', 'POS': 'NOUN'}/nsubj  \\\n",
       "story      NOUN                                         0   \n",
       "attack     NOUN                                         0   \n",
       "social     ADJ                                          0   \n",
       "bad        ADJ                                          0   \n",
       "market     NOUN                                         0   \n",
       "...                                                   ...   \n",
       "punch      VERB                                         0   \n",
       "nursery    NOUN                                         0   \n",
       "rhyme      NOUN                                         0   \n",
       "axiomatize VERB                                         0   \n",
       "formalist  ADJ                                          0   \n",
       "\n",
       "                 {'lemma': 'people', 'POS': 'NOUN'}/nsubj  \\\n",
       "story      NOUN                                         0   \n",
       "attack     NOUN                                         0   \n",
       "social     ADJ                                          0   \n",
       "bad        ADJ                                          0   \n",
       "market     NOUN                                         0   \n",
       "...                                                   ...   \n",
       "punch      VERB                                         0   \n",
       "nursery    NOUN                                         0   \n",
       "rhyme      NOUN                                         0   \n",
       "axiomatize VERB                                         0   \n",
       "formalist  ADJ                                          0   \n",
       "\n",
       "                 {'lemma': 'remain', 'POS': 'VERB'}/nsubj_amod  ...  \\\n",
       "story      NOUN                                              0  ...   \n",
       "attack     NOUN                                              0  ...   \n",
       "social     ADJ                                               0  ...   \n",
       "bad        ADJ                                               0  ...   \n",
       "market     NOUN                                              0  ...   \n",
       "...                                                        ...  ...   \n",
       "punch      VERB                                              0  ...   \n",
       "nursery    NOUN                                              0  ...   \n",
       "rhyme      NOUN                                              0  ...   \n",
       "axiomatize VERB                                              0  ...   \n",
       "formalist  ADJ                                               0  ...   \n",
       "\n",
       "                 {'lemma': 'attack', 'POS': 'NOUN'}/conj_nsubj  \\\n",
       "story      NOUN                                              0   \n",
       "attack     NOUN                                              0   \n",
       "social     ADJ                                               0   \n",
       "bad        ADJ                                               0   \n",
       "market     NOUN                                              0   \n",
       "...                                                        ...   \n",
       "punch      VERB                                              0   \n",
       "nursery    NOUN                                              0   \n",
       "rhyme      NOUN                                              0   \n",
       "axiomatize VERB                                              0   \n",
       "formalist  ADJ                                               0   \n",
       "\n",
       "                 {'lemma': 'derive', 'POS': 'VERB'}/nsubj_case_of  \\\n",
       "story      NOUN                                                 1   \n",
       "attack     NOUN                                                 0   \n",
       "social     ADJ                                                  0   \n",
       "bad        ADJ                                                  0   \n",
       "market     NOUN                                                 0   \n",
       "...                                                           ...   \n",
       "punch      VERB                                                 0   \n",
       "nursery    NOUN                                                 0   \n",
       "rhyme      NOUN                                                 0   \n",
       "axiomatize VERB                                                 0   \n",
       "formalist  ADJ                                                  0   \n",
       "\n",
       "                 {'lemma': 'story', 'POS': 'NOUN'}/nsubj_case_of  \\\n",
       "story      NOUN                                                0   \n",
       "attack     NOUN                                                0   \n",
       "social     ADJ                                                 0   \n",
       "bad        ADJ                                                 0   \n",
       "market     NOUN                                                0   \n",
       "...                                                          ...   \n",
       "punch      VERB                                                0   \n",
       "nursery    NOUN                                                0   \n",
       "rhyme      NOUN                                                0   \n",
       "axiomatize VERB                                                0   \n",
       "formalist  ADJ                                                 0   \n",
       "\n",
       "                 {'lemma': 'usage', 'POS': 'NOUN'}/conj_nsubj  \\\n",
       "story      NOUN                                             0   \n",
       "attack     NOUN                                             0   \n",
       "social     ADJ                                              0   \n",
       "bad        ADJ                                              0   \n",
       "market     NOUN                                             0   \n",
       "...                                                       ...   \n",
       "punch      VERB                                             0   \n",
       "nursery    NOUN                                             0   \n",
       "rhyme      NOUN                                             0   \n",
       "axiomatize VERB                                             0   \n",
       "formalist  ADJ                                              0   \n",
       "\n",
       "                 {'lemma': 'boethius', 'POS': 'NOUN'}/nsubj  \\\n",
       "story      NOUN                                           0   \n",
       "attack     NOUN                                           0   \n",
       "social     ADJ                                            0   \n",
       "bad        ADJ                                            0   \n",
       "market     NOUN                                           0   \n",
       "...                                                     ...   \n",
       "punch      VERB                                           0   \n",
       "nursery    NOUN                                           0   \n",
       "rhyme      NOUN                                           0   \n",
       "axiomatize VERB                                           0   \n",
       "formalist  ADJ                                            0   \n",
       "\n",
       "                 {'lemma': 'translate', 'POS': 'VERB'}/conj_nsubj  \\\n",
       "story      NOUN                                                 0   \n",
       "attack     NOUN                                                 0   \n",
       "social     ADJ                                                  0   \n",
       "bad        ADJ                                                  0   \n",
       "market     NOUN                                                 0   \n",
       "...                                                           ...   \n",
       "punch      VERB                                                 0   \n",
       "nursery    NOUN                                                 0   \n",
       "rhyme      NOUN                                                 0   \n",
       "axiomatize VERB                                                 0   \n",
       "formalist  ADJ                                                  0   \n",
       "\n",
       "                 {'lemma': 'fact', 'POS': 'NOUN'}/nsubj_case_of  \\\n",
       "story      NOUN                                               0   \n",
       "attack     NOUN                                               0   \n",
       "social     ADJ                                                0   \n",
       "bad        ADJ                                                0   \n",
       "market     NOUN                                               0   \n",
       "...                                                         ...   \n",
       "punch      VERB                                               0   \n",
       "nursery    NOUN                                               0   \n",
       "rhyme      NOUN                                               0   \n",
       "axiomatize VERB                                               0   \n",
       "formalist  ADJ                                                0   \n",
       "\n",
       "                 {'lemma': 'formalist', 'POS': 'ADJ'}/nsubj_amod  \\\n",
       "story      NOUN                                                0   \n",
       "attack     NOUN                                                0   \n",
       "social     ADJ                                                 0   \n",
       "bad        ADJ                                                 0   \n",
       "market     NOUN                                                0   \n",
       "...                                                          ...   \n",
       "punch      VERB                                                0   \n",
       "nursery    NOUN                                                0   \n",
       "rhyme      NOUN                                                0   \n",
       "axiomatize VERB                                                0   \n",
       "formalist  ADJ                                                 0   \n",
       "\n",
       "                 {'lemma': 'truth', 'POS': 'NOUN'}/acl:relcl_nsubj  \\\n",
       "story      NOUN                                                  0   \n",
       "attack     NOUN                                                  0   \n",
       "social     ADJ                                                   0   \n",
       "bad        ADJ                                                   0   \n",
       "market     NOUN                                                  0   \n",
       "...                                                            ...   \n",
       "punch      VERB                                                  0   \n",
       "nursery    NOUN                                                  0   \n",
       "rhyme      NOUN                                                  0   \n",
       "axiomatize VERB                                                  0   \n",
       "formalist  ADJ                                                   0   \n",
       "\n",
       "                 {'lemma': 'statement', 'POS': 'NOUN'}/acl:relcl_nsubj  \n",
       "story      NOUN                                                  0      \n",
       "attack     NOUN                                                  0      \n",
       "social     ADJ                                                   0      \n",
       "bad        ADJ                                                   0      \n",
       "market     NOUN                                                  0      \n",
       "...                                                            ...      \n",
       "punch      VERB                                                  0      \n",
       "nursery    NOUN                                                  0      \n",
       "rhyme      NOUN                                                  0      \n",
       "axiomatize VERB                                                  0      \n",
       "formalist  ADJ                                                   0      \n",
       "\n",
       "[11077 rows x 15597 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coocc_count = mangoes.counting.count_cooccurrence(corpus,  \n",
    "                                                target_vocabulary, \n",
    "                                                context=dependency_context,\n",
    "                                                )\n",
    "\n",
    "coocc_count.pprint(display=display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "limited-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Token(lemma='story', POS='NOUN'),\n",
       " Token(lemma='attack', POS='NOUN'),\n",
       " Token(lemma='social', POS='ADJ'),\n",
       " Token(lemma='bad', POS='ADJ'),\n",
       " Token(lemma='market', POS='NOUN'),\n",
       " Token(lemma='house', POS='NOUN'),\n",
       " Token(lemma='territory', POS='NOUN'),\n",
       " Token(lemma='original', POS='ADJ'),\n",
       " Token(lemma='claim', POS='VERB'),\n",
       " Token(lemma='style', POS='NOUN'),\n",
       " Token(lemma='horse', POS='NOUN'),\n",
       " Token(lemma='text', POS='NOUN'),\n",
       " Token(lemma='western', POS='ADJ'),\n",
       " Token(lemma='decision', POS='NOUN'),\n",
       " Token(lemma='true', POS='ADJ'),\n",
       " Token(lemma='friendly', POS='ADJ'),\n",
       " Token(lemma='file', POS='NOUN'),\n",
       " Token(lemma='choose', POS='VERB'),\n",
       " Token(lemma='discuss', POS='VERB'),\n",
       " Token(lemma='mention', POS='VERB')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"target words\")\n",
    "coocc_count.words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ranking-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"{'lemma': 'detonate', 'POS': 'VERB'}/nsubj\",\n",
       " \"{'lemma': 'guerrilla', 'POS': 'NOUN'}/nsubj\",\n",
       " \"{'lemma': 'hope', 'POS': 'VERB'}/advcl_nsubj\",\n",
       " \"{'lemma': 'tradeoff', 'POS': 'NOUN'}/nsubj\",\n",
       " \"{'lemma': 'move', 'POS': 'NOUN'}/nsubj\",\n",
       " \"{'lemma': 'suckup', 'POS': 'NOUN'}/acl_nsubj\",\n",
       " \"{'lemma': 'people', 'POS': 'NOUN'}/conj_nsubj\",\n",
       " \"{'lemma': 'suckup', 'POS': 'NOUN'}/nsubj\",\n",
       " \"{'lemma': 'people', 'POS': 'NOUN'}/nsubj\",\n",
       " \"{'lemma': 'remain', 'POS': 'VERB'}/nsubj_amod\",\n",
       " \"{'lemma': 'remain', 'POS': 'VERB'}/nsubj\",\n",
       " \"{'lemma': 'condemn', 'POS': 'VERB'}/nsubj\",\n",
       " \"{'lemma': 'condemn', 'POS': 'VERB'}/nsubj_case_of\",\n",
       " \"{'lemma': 'board', 'POS': 'NOUN'}/nsubj\",\n",
       " \"{'lemma': 'cleric', 'POS': 'NOUN'}/nsubj_case_of\",\n",
       " \"{'lemma': 'say', 'POS': 'VERB'}/nsubj_compound\",\n",
       " \"{'lemma': 'say', 'POS': 'VERB'}/ccomp_nsubj\",\n",
       " \"{'lemma': 'criminal', 'POS': 'ADJ'}/nsubj\",\n",
       " \"{'lemma': 'attack', 'POS': 'NOUN'}/nsubj\",\n",
       " \"{'lemma': 'give', 'POS': 'VERB'}/nsubj\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"context words\")\n",
    "coocc_count.contexts_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "grand-halifax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11077, 15597)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coocc_count.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "daily-vampire",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target word:  Token(lemma='text', POS='NOUN')\n",
      "close words\n",
      "[(Token(lemma='drop', POS='NOUN'), 0.6407893959464501),\n",
      " (Token(lemma='diamond', POS='NOUN'), 0.6407893959464501),\n",
      " (Token(lemma='landmass', POS='NOUN'), 0.6407893959464501),\n",
      " (Token(lemma='nose', POS='NOUN'), 0.6407893959464501),\n",
      " (Token(lemma='tonne', POS='NOUN'), 0.6787122684390005),\n",
      " (Token(lemma='skin', POS='NOUN'), 0.7284623066791478),\n",
      " (Token(lemma='sample', POS='NOUN'), 0.7407620763173937),\n",
      " (Token(lemma='syllabary', POS='NOUN'), 0.792609661053915),\n",
      " (Token(lemma='cel', POS='NOUN'), 0.8203946979732251),\n",
      " (Token(lemma='commitment', POS='NOUN'), 0.8203946979732251),\n",
      " (Token(lemma='cabin', POS='NOUN'), 0.8203946979732251),\n",
      " (Token(lemma='listing', POS='NOUN'), 0.8203946979732251)]\n"
     ]
    }
   ],
   "source": [
    "i = 11\n",
    "print(\"target word: \", target_vocabulary[i])\n",
    "print(\"close words\")\n",
    "pprint.pprint(coocc_count.get_closest_words(target_vocabulary[i], 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-allocation",
   "metadata": {},
   "source": [
    "### Weighting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-validity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmi = mangoes.weighting.PPMI()\n",
    "svd = mangoes.reduction.SVD(dimensions=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = mangoes.create_representation(coocc_count, weighting=ppmi, reduction=svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-renewal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embeddings.pprint(display=display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embeddings \n",
    "# embedding_path = os.path.join(OUTPUT_PATH,\n",
    "#                               \"embeddings/ppmi_svd_{}target_words_deprel\".format(len(target_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings.save(embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embedding \n",
    "# embeddings = mangoes.Embeddings.load(embedding_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-adolescent",
   "metadata": {},
   "source": [
    "# Explore Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-section",
   "metadata": {},
   "source": [
    "### Closest Words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-oxide",
   "metadata": {},
   "source": [
    "#### Similarities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = {0: \"cityblock\",\n",
    "        1: \"cosine\", \n",
    "        2: \"euclidean\", \n",
    "        3: \"l1\", \n",
    "        4:\"l2\", \n",
    "        5:\"manhattan\",\n",
    "        6:\"braycurtis\", \n",
    "        7:\"canberra\", \n",
    "        8:\"chebyshev\", \n",
    "        9:\"correlation\", \n",
    "        10:\"dice\", \n",
    "        11:\"hamming\", \n",
    "        12:\"jaccard\", \n",
    "        13:\"kulsinski\", \n",
    "        14:\"mahalanobis\", \n",
    "       15: \"minkowski\", \n",
    "       16: \"rogerstanimoto\", \n",
    "       17: \"russellrao\", \n",
    "       18: \"seuclidean\", \n",
    "        19:\"sokalmichener\", \n",
    "        20:\"sokalsneath\", \n",
    "       21: \"sqeuclidean\", \n",
    "       22: \"yule\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "nb = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-discretion",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = {word: pd.Series([w for w, _ in embeddings.get_closest_words(word, nb=nb, metric=sims[i])], index=range(1,nb+1))\n",
    "          for word in embeddings.words[100:200:10]}\n",
    "print(f\"similarity measure: {sims[i]}\")\n",
    "print(pd.DataFrame(result).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floppy-indiana",
   "metadata": {},
   "source": [
    "### Analogies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what words are available \n",
    "question = \"king queen male\"\n",
    "ans = \"female\"\n",
    "for w in (question.split() + [ans]):\n",
    "    try:\n",
    "        embeddings.words.word_index[w]\n",
    "        print(f\"'{w}' exists\")\n",
    "    except KeyError:\n",
    "        print(f\"'{w}'  doesn't exist in embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can resolve analogy according to a representation using the analogy() method\n",
    "# Here, we will display the results of some examples :\n",
    "for analogy in [question]:\n",
    "    print(analogy, '->', embeddings.analogy(analogy,5).using_cosadd)\n",
    "    print(analogy, '->', embeddings.analogy(analogy,5).using_cosmul)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-catch",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import mangoes.visualize\n",
    "plt.figure()\n",
    "\n",
    "# 1. distances between the words\n",
    "ax = plt.subplot(221, projection='polar')\n",
    "mangoes.visualize.plot_distances(embeddings, ax)\n",
    "\n",
    "# 2. isotropy\n",
    "ax = plt.subplot(222)\n",
    "mangoes.visualize.plot_isotropy(embeddings, ax)\n",
    "\n",
    "# 3. t-sne\n",
    "plt.subplot(212)\n",
    "mangoes.visualize.plot_tsne(embeddings)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-cheese",
   "metadata": {},
   "source": [
    "# Evalutaion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-instrumentation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Evaluate\n",
    "import mangoes.evaluation.analogy\n",
    "\n",
    "google_dataset = mangoes.evaluation.analogy.GOOGLE\n",
    "msr_dataset = mangoes.evaluation.analogy.MSR\n",
    "\n",
    "analogy_evaluation = mangoes.evaluation.analogy.Evaluation(embeddings, google_dataset, msr_dataset)\n",
    "print(analogy_evaluation.get_report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-figure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:namre_dev]",
   "language": "python",
   "name": "conda-env-namre_dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
